\documentclass[10pt,a4paper]{article}
\usepackage{amsmath,amssymb,bm,makeidx,subfigure}
\usepackage[italian,english]{babel}
\usepackage[center,small]{caption}[2007/01/07]
\usepackage{fancyhdr}
\usepackage{color}
\usepackage{graphicx}

\definecolor{blu}{rgb}{0,0,1}
\definecolor{verde}{rgb}{0,1,0}
\definecolor{rosso}{rgb}{1,0,0}
\definecolor{viola}{rgb}{1,0,1}
\definecolor{arancio}{rgb}{1,0.5,0}
\definecolor{celeste}{rgb}{0,1,1}
\definecolor{rosa}{rgb}{1,0.3,0.5}

\oddsidemargin = 12pt
\topmargin = 0pt
\textwidth = 440pt
\textheight = 650pt

\makeindex

\begin{document}

\title{Drell-Yan cross section in TMD factorisation}

\author{Valerio Bertone}

%\institution{$^{a}$PH Department, TH Unit, CERN, CH-1211 Geneva 23, Switzerland}
\maketitle

%\begin{abstract}
%In this document 
%\end{abstract}
\tableofcontents{}

\section{Structure of the observables}

Let us start from Eq.~(2.6) of Ref.~\cite{Scimemi:2017etj}, that is
the fully differential cross section for lepton-pair production in the
region in which the TMD factorisation applies, $i.e.$ $q_T \ll
Q$. After some minor manipulations, it reads:
\begin{equation}\label{eq:crosssection}
  \frac{d\sigma}{dQ dy dq_T} =
  \frac{16\pi\alpha^2q_T}{9 Q^3} H(Q,\mu) \sum_q C_q(Q)
  \int\frac{d^2\mathbf{b}}{4\pi} e^{i \mathbf{b}\cdot \mathbf{q}_T} \overline{F}_q(x_1,\mathbf{b};\mu,\zeta) \overline{F}_{\bar{q}}(x_2,\mathbf{b};\mu,\zeta)\,,
\end{equation}
where $Q$, $y$, and $q_T$ are the invariant mass, the rapidity, and
the transverse momentum of the lepton pair, respectively, while
$\alpha$ is the electromagnetic coupling, $H$ is the appropriate QCD
hard factor that can be perturbatively computed, and $C_q$ are the
effective electroweak charges. In addition, the variables $x_1$ and
$x_2$ are functions of $Q$ and $y$ and are given by:
\begin{equation}\label{eq:Bjorkenx12}
  x_{1,2} = \frac{Q}{\sqrt{s}}e^{\pm y}\,,
\end{equation}
being $\sqrt{s}$ the centre-of-mass energy of the collision. In
Eq.~(\ref{eq:crosssection}) we are using the short-hand notation:
\begin{equation}
\overline{F}_q(x,\mathbf{b};\mu,\zeta) \equiv xF_q(x,\mathbf{b};\mu,\zeta)\,,
\end{equation}
that is convenient for the implementation. The scales $\mu$ and
$\zeta$ are introduced as a consequence of the removal of UV and
rapidity divergences in the definition of the TMDs. Despite these
scales are arbitrary scales, they are typically chosen
$\mu=\sqrt{\zeta}=Q$. Therefore, for all practical purposes their
presence is fictitious.

The computation-intensive part of Eq.(\ref{eq:crosssection}) has the
form of the integral:
\begin{equation}\label{eq:integral}
I_{ij}(x_1,x_2,q_T;\mu,\zeta)=\int\frac{d^2\mathbf{b}}{4\pi} e^{i \mathbf{b}\cdot \mathbf{q}_T} \overline{F}_i(x_1,\mathbf{b};\mu,\zeta) \overline{F}_{j}(x_2,\mathbf{b};\mu,\zeta)\,.
\end{equation}
where $\overline{F}_{i(j)}$ are combinations of evolved TMD PDFs. At
this stage, for convenience, $i$ and $j$ do not coincide with $q$ and
$\bar{q}$ but they are linked through a simple linear
transformation. The integral over the bidimensional impact parameter
\textbf{b} has to be taken. However, $\overline{F}_{i(j)}$ only depend
on the absolute value of \textbf{b}, therefore Eq.~(\ref{eq:integral})
can be written as:
\begin{equation}\label{eq:integral2}
I_{ij}(x_1,x_2,q_T;\mu,\zeta)=\frac12\int_0^\infty db\,b J_0(bq_T)  \overline{F}_i(x_1,b;\mu,\zeta) \overline{F}_{j}(x_2,b;\mu,\zeta)\,.
\end{equation}
where $J_0$ is the zero-th order Bessel function of the first kind
whose integral representation is:
\begin{equation}
J_0(x) = \frac1{2\pi}\int_0^{2\pi} d\theta e^{ix\cos(\theta)}\,.
\end{equation}
The evolved quark TMD PDF $\overline{F}_i$ at the final scales $\mu$
and $\zeta$ is obtained by multiplying the same distribution at the
initial scales $\mu_0$ and $\zeta_0$ by a single evolution factor
$R_q$(\footnote{Note that in Eq.~(\ref{eq:crosssection}) the gluon TMD
  PDF $\overline{F}_g$ is not involved. If also the gluon TMD PDF was
  involved, it would evolve by means of a different evolution factor
  $R_g$.}).  that is:
\begin{equation}\label{eq:evolution}
  \overline{F}_i(x,b;\mu,\zeta) = R_q(\mu_0,\zeta_0\rightarrow \mu,\zeta;b)
  \overline{F}_i(x,b;\mu_0,\zeta_0)\,.
\end{equation}

The initial scale TMD PDFs at small values $b$ can be written as:
\begin{equation}\label{eq:LOconv}
\overline{F}_i(x,b;\mu_0,\zeta_0) = \sum_{j=g,q(\bar{q})}x\int_x^1\frac{dy}{y}C_{ij}(y;\mu_0,\zeta_0)f_j\left(\frac{x}{y},\mu_0\right)\,,
\end{equation}
where $f_j$ are the collinear PDFs (including the gluon) and $C_{ij}$
are the so-called matching functions that are perturbatively
computable and are currently known to NNLO, $i.e.$
$\mathcal{O}(\alpha_s^2)$. If we define:
\begin{equation}
\overline{f}_i\left(x,\mu_0\right) = xf_i\left(x,\mu_0\right)\,,
\end{equation}
Eq.~(\ref{eq:LOconv}) can be written as:
\begin{equation}\label{eq:LOconvMod}
\overline{F}_i(x,b;\mu_0,\zeta_0) =
\sum_{j=g,q(\bar{q})}\int_x^1dy\,C_{ij}(y;\mu_0,\zeta_0)  \overline{f}_i\left(\frac{x}{y},\mu_0\right)\,.
\end{equation}
Putting Eqs.~(\ref{eq:evolution}) and~(\ref{eq:LOconvMod}), one finds:
\begin{equation}\label{eq:pertTMD}
  \overline{F}_i(x,b;\mu,\zeta) = R_q(\mu_0,\zeta_0\rightarrow \mu,\zeta;b)
  \sum_{j=g,q(\bar{q})}\int_x^1dy\,C_{ij}(y;\mu_0,\zeta_0)  \overline{f}_i\left(\frac{x}{y},\mu_0\right)\,.
\end{equation}

Matching and evolution are affected by non-perturbative effects that
become relevant at large $b$. In order to account for such effects,
one usually introduces a phenomenological function $f_{\rm NP}$. In
the traditional approach (CSS~\cite{Collins:2011zzd}), the $b$-space
TMDs get a multiplicative correction that does not depend on the
flavour. In addition, the perturbative content of the TMDs is smoothly
damped away at large $b$ by introducing the so-called
$b_*$-prescription:
\begin{equation}\label{eq:LOconvNP1}
  \overline{F}_i(x,b;\mu,\zeta) \rightarrow \overline{F}_i(x,b_*(b);\mu,\zeta) f_{\rm NP}(x,b,\zeta)\,,
\end{equation}
where $b_*\equiv b_*(b)$ is a monotonic function of the impact
parameter $b$ such that:
\begin{equation}
  \lim_{b\rightarrow 0}
  b_*(b) = b_{\rm min}\quad\mbox{and}\quad\lim_{b\rightarrow \infty}
  b_*(b) = b_{\rm max}\,,
\end{equation}
being $b_{\rm min}$ and $b_{\rm max}$ constant values both in the
perturbative region. Including the non-perturbative function,
Eq.~(\ref{eq:integral2}) becomes:
\begin{equation}\label{eq:integral3}
\begin{array}{l}
\displaystyle I_{ij}(x_1,x_2,q_T;\mu,\zeta) = \displaystyle \int_0^\infty db\,J_0(bq_T)\left[\frac{b}2 
\overline{F}_i(x_1,b_*(b);\mu,\zeta) \overline{F}_{j}(x_2,b_*(b);\mu,\zeta) f_{\rm NP}(x_1,b,\zeta)
  f_{\rm NP}(x_2,b,\zeta) \right]\\
\\
\displaystyle =\frac{1}{q_T}\int_0^\infty d\bar{b}\,J_0(\bar{b})\left[\frac{\bar{b}}{2q_T} 
\overline{F}_i(x_1,b_*\left(\frac{\bar{b}}{q_T}\right);\mu,\zeta) \overline{F}_{j}(x_2,,b_*\left(\frac{\bar{b}}{q_T}\right);\mu,\zeta) f_{\rm NP}\left(x_1,\frac{\bar{b}}{q_T},\zeta\right)
  f_{\rm NP}\left(x_2,\frac{\bar{b}}{q_T},\zeta\right) \right]
\,.
\end{array}
\end{equation}
Eq.~(\ref{eq:integral3}) is a Hankel tranform and can be efficiently
computed using the so-called Ogata quadrature~\cite{Ogata:quadrature}.
Effectively, the computation of the integral in
Eq.~(\ref{eq:integral}) is achieved through a weighted sum:
\begin{equation}\label{eq:ogataquadrature}
\begin{array}{rcl}
I_{ij}(x_1,x_2,q_T;\mu,\zeta) &\simeq& \displaystyle
                                                     \frac1{q_T}\sum_{n=1}^N
                                                     \frac{w_n^{(0)}z_n^{(0)}}{2q_T} 
\overline{F}_i\left(x_1,b_*\left
                                       (\frac{z_n^{(0)}}{q_T}\right);\mu,\zeta\right) \overline{F}_j\left(x_2,b_*\left (\frac{z_n^{(0)}}{q_T}\right);\mu,\zeta\right)\\
\\
&\times&\displaystyle f_{\rm NP}\left(x_1,\frac{z_n^{(0)}}{q_T},\zeta\right)
  f_{\rm NP}\left(x_2,\frac{z_n^{(0)}}{q_T},\zeta\right)\,,
\end{array}
\end{equation}
where the unscaled coordinates $z_n^{(0)}$ and the weights $w_n^{(0)}$
can be precomputed in terms of the zero's of the Bessel function $J_0$
and one single parameter (see Ref.~\cite{Ogata:quadrature} for more
details, specifically Eqs.~(5.1) and~(5.2) or
Appendix~\ref{app:OgataQuadrature} for the relevant formula to compute
the unscaled coordinates and the weights)\footnote{The superscript 0
  in $z_n^{(0)}$ and $w_n^{(0)}$ indicates that here we are performing
  a Hankel tranform that involves the Bessel function of degree zero
  $J_0$. This is useful in view of the next section in which the
  integration over $q_T$ will give rise to a similar Hankel transform
  with $J_0$ replaced by $J_1$. Also in that case the Ogata quadrature
  algorithm can be applied but coordinates and weights will be
  different.}. Based on the (empirically verified) assumption that the
absolute value of each term in the sum in the r.h.s. of
Eq.~(\ref{eq:ogataquadrature}) is smaller than that of the preceding
one, the truncation number $N$ is chosen dynamically in such a way
that the $(N+1)$-th term is smaller in absolute value than a
user-defined cutoff relatively to the sum of the preceding $N$ terms.

Eq.~(\ref{eq:ogataquadrature}) factors out the non-perturbative part
of the calculation represented by $f_{\rm NP}$ from the perturbative
content. This is done on purpose to devise a method in which the
perturbative content is precomputed and numerically convoluted with
the non-perturbative functions \textit{a posteriori}. This is
convenient in view of a fit of the function $f_{\rm NP}$.

As customary in QCD, the most convenient basis for the matching in
Eq.~(\ref{eq:LOconv}) is the so-called ``evolution'' basis
(\textit{i.e.} $\Sigma$, $V$, $T_3$, $V_3$, etc.). In fact, in this
basis the operator matrix $C_{ij}$ is almost diagonal with the only
exception of crossing terms that couple the gluon and the singlet
$\Sigma$ distributions. As a consequence, this is the most convenient
basis for the computation of $I_{ij}$. On the other hand, TMDs in
Eq.~(\ref{eq:crosssection}) appear in the so-called ``physical'' basis
(\textit{i.e.} $d$, $\bar{d}$, $u$, $\bar{u}$, etc.). Therefore, we
need to rotate $F_{i(j)}$ from the evolution basis, over which the
indices $i$ and $j$ run, to the physical basis. This is done by means
of an appropriate constant matrix $T$, so that:
\begin{equation}\label{eq:lumiInterRot}
\overline{F}_{q}(x_1,b;\mu,\zeta)= \sum_{i}T_{qi}F_{i}(x_1,b;\mu,\zeta)\,,
\end{equation}
and similarly for $\overline{F}_{\bar{q}}$. Putting all pieces
together, one can conveniently write the cross section in
Eq.~(\ref{eq:crosssection}) as:
\begin{equation}\label{eq:fastdiffxsec}
  \frac{d\sigma}{dQ dy dq_T} \simeq\sum_{n=1}^N w_n^{(0)} \frac{z_n^{(0)}}{q_T}S\left(x_1,x_2,\frac{z_n^{(0)}}{q_T};\mu,\zeta\right) f_{\rm NP}\left(x_1,\frac{z_n^{(0)}}{q_T},\zeta\right) f_{\rm NP}\left(x_2,\frac{z_n^{(0)}}{q_T},\zeta\right)\,,
\end{equation}
with:
\begin{equation}\label{eq:pertfact}
S(x_1,x_2,b;\mu,\zeta) =\frac{8\pi\alpha^2}{9 Q^3}
    H(Q,\mu) \sum_q C_q(Q) \left[
\overline{F}_q\left(x_1,b_*(b);\mu,\zeta \right)\right] \left[
\overline{F}_{\bar{q}}\left(x_2,b_*(b);\mu,\zeta \right)\right]\,.
\end{equation}
Eq.~(\ref{eq:fastdiffxsec}) allows one to precompute the weights $S$
in such a way that the differential cross section in
Eq.~(\ref{eq:crosssection}) can be computed as a simple weighted sum
of the non-perturbative contribution. A misleading aspect of
Eq.~(\ref{eq:pertfact}) is the fact that $S$ has five arguments. In
actual facts, $S$ only depends on three independent variables. The
reason is that $\mu$ and $\zeta$ are usually taken to be proportional
to $Q$ by a constant factor. In addition $x_1$ and $x_2$ depend on $Q$
and $y$ through Eq.~(\ref{eq:Bjorkenx12}). Therefore, the full
dependence on the kinematics of the final state of
Eq.~(\ref{eq:crosssection}) can be specified by $Q$, $y$ and $q_T$.

\section{Integrating over the final-state kinematic variables}

Despite Eq.~(\ref{eq:fastdiffxsec}) provides a powerful tool for a
fast computation of cross sections, it is often not sufficient to
allow for a direct comparison to experimental data. The reason is that
experimental measurements of differential distributions are usually
delivered as integrated over finite regions of the final-state
kinematic phase space. In other words, experiments measure quantities
like:
\begin{equation}\label{eq:Intcrosssection}
\widetilde{\sigma}=\int_{Q_{\rm min}}^{Q_{\rm max}}dQ \int_{y_{\rm min}}^{y_{\rm max}}dy \int_{q_{T,\rm min}}^{q_{T,\rm max}}dq_T\left[\frac{d\sigma}{dQ dy dq_T} \right]\,.
\end{equation}
As a consequence, in order to guarantee performance, we need to
include the integrations above in the precomputed factors. 

\subsection{Integrating over $q_T$}

The integration over bins in $q_T$ can be carried out analytically
exploiting the following property of Bessel's function:
\begin{equation}
\frac{d}{dx}\left[x^mJ_m(x)\right]=x^mJ_{m-1}(x)\,,
\end{equation}
that leads to:
\begin{equation}\label{eq:besselproperty}
\int dx\,x J_0(x) = xJ_1(x)\quad\Rightarrow\quad \int_{x_1}^{x_2}
dx\,x J_0(x) = x_2J_1(x_2) - x_1J_1(x_1)\,.
\end{equation}
To see it, we observe that the differential cross section in
Eq.~(\ref{eq:crosssection}) has the following structure:
\begin{equation}
  \frac{d\sigma}{dQ dy dq_T} \propto \int_0^\infty db\, q_T  J_0(bq_T)\dots
\end{equation}
where the ellipses indicate terms that do not depend on
$q_T$. Therefore, using Eq.~(\ref{eq:besselproperty}) we find:
\begin{equation}
\begin{array}{l}
\displaystyle \int_{q_{T,\rm min}}^{q_{T,\rm
  max}}dq_T\left[\frac{d\sigma}{dQ dy dq_T} \right] \propto \int_0^\infty db\,
  \int_{q_{T,\rm min}}^{q_{T,\rm
  max}} dq_T\,   q_T J_0(bq_T)\dots= \\
\\
\displaystyle \int_0^\infty \frac{db}{b^2}\,
  \int_{bq_{T,\rm min}}^{bq_{T,\rm
  max}} dx\,   x J_0(x)\dots=\int_0^\infty \frac{db}{b}\left[q_{T,\rm
  max}J_1(bq_{T,\rm max}) - q_{T,\rm
  min}J_1(bq_{T,\rm min})\right]\dots\,.
\end{array}
\end{equation}
Therefore, defining:
\begin{equation}
K(q_T) \equiv \int dq_T\left[\frac{d\sigma}{dQ dy dq_T} \right]
\end{equation}
as the indefinite integral over $q_T$ of the cross section in
Eq.~(\ref{eq:crosssection}), we have that:
\begin{equation}\label{eq:primitive}
\int_{q_{T,\rm min}}^{q_{T,\rm
  max}}dq_T\left[\frac{d\sigma}{dQ dy dq_T} \right] = K(Q,y,q_{T,\rm max})
- K(Q,y,q_{T,\rm min})\,,
\end{equation}
with:
\begin{equation}\label{eq:Kexplicit}
\begin{array}{l}
 \displaystyle K(Q,y,q_T) =
  \frac{8\pi\alpha^2q_T}{9 Q^3} H(Q,\mu) \\
\\
\displaystyle \times
  \int_0^\infty db\, J_1(bq_T) \sum_q C_q(Q)\overline{F}_q(x_1,b;\mu,\zeta) \overline{F}_{\bar{q}}(x_2,b;\mu,\zeta) f_{\rm NP}(x_1,b,\zeta)
  f_{\rm NP}(x_2,b,\zeta)\,,
\end{array}
\end{equation}
that can be computed using the Ogata quadrature as:
\begin{equation}
  K(Q,y,q_T) \simeq \sum_{n=1}^N w_n^{(1)} S\left(x_1,x_2,\frac{z_n^{(1)}}{q_T};\mu,\zeta\right) f_{\rm NP}\left(x_1,\frac{z_n^{(1)}}{q_T},\zeta\right) f_{\rm NP}\left(x_2,\frac{z_n^{(1)}}{q_T},\zeta\right)\,,
\end{equation}
with $S$ defined in Eq.~(\ref{eq:pertfact}). The unscaled coordinates
$z_n^{(1)}$ and the weights $w_n^{(1)}$ can again be precomputed and
stored in terms of the zero's of the Bessel function
$J_1$. Eq.~(\ref{eq:primitive}) reduces the integration in $q_T$ to a
calculation completely analogous to the unintegrated cross
section. This is particularly convenient because it avoids the
computation a numerical integration.

\subsubsection{Kinematic cuts}\label{sec:kincuts}

In the presence of kinematic cuts, such as those on the final-state
leptons in Drell-Yan, the analytic integration over $q_T$ discussed
above cannot be performed. The reason is that the implementation of
these cuts effectively introduces a $q_T$-dependent function
$\mathcal{P}$(\footnote{In fact, $\mathcal{P}$ also depends on the
  invariant mass $Q$ and the rapidity $y$ of the lepton pair that also
  need to be integrated over.}) in the integral:
\begin{equation}
  \frac{d\sigma}{dQ dy dq_T} \propto \int_0^\infty db\, q_T  J_0(bq_T)\mathcal{P}(q_T)\dots\,,
\end{equation}
that prevents the direct use of Eq.~(\ref{eq:besselproperty}).
% However, integrating by parts, we can write(\footnote{Notice that the
%   lower bound of the integral in the r.h.s., that is 0 here, is
%   actually arbitrary because the final result does not depend on
%   it.}):
% \begin{equation}
%   \int_{q_{T,\rm min}}^{q_{T,\rm
%       max}} dq_T\, q_T J_0(bq_T) \mathcal{P}(q_T)= \frac{1}{b}\left[q_T J_1(bq_T) \mathcal{P}(q_T)- \int_{0}^{q_{T}} d\bar{q}_T\, \bar{q}_T J_1(b\bar{q}_T) \mathcal{P}'(\bar{q}_T)\right]\Bigg|_{q_{T,\rm min}}^{q_{T,\rm
%       max}}\,.
% \end{equation}
% Now, if we assume that $\mathcal{P}$ is a slowly-varying function of
% $q_T$ (\textit{i.e.} $\mathcal{P}'$ is small), we could, in first
% approximation, neglect the second term in the r.h.s. of the equation
% above. Unfortunately, despite $\mathcal{P}$ is an actual
% slowly-varying function of $q_T$, the contribution of the integral in
% the r.h.s. is still large, particularly at large $q_T$. This is mostly
% due to the fact that the integral over $b$ of $J_1(bq_T)$,
% particularly for large values of $q_T$, is numerically large.
Since $\mathcal{P}$ is a slowly-varying function of $q_T$ over the
typical bin size, we can approximate the integral over the bins in
$q_T$ as:
\begin{equation}\label{eq:intbyparts}
\begin{array}{rcl}
\displaystyle  \int_{q_{T,\rm min}}^{q_{T,\rm
      max}} dq_T\, q_T J_0(bq_T) \mathcal{P}(q_T)&\simeq&\displaystyle
  \mathcal{P}\left(\frac{q_{T,\rm max}+q_{T,\rm min}}2\right)\int_{q_{T,\rm min}}^{q_{T,\rm
      max}} dq_T\, q_T J_0(bq_T) \\
\\
&=& \displaystyle\mathcal{P}\left(\frac{q_{T,\rm max}+q_{T,\rm
    min}}2\right) \frac{1}{b}\left[q_{T,\rm max} J_1(bq_{T,\rm max}) - q_{T,\rm min} J_1(bq_{T,\rm min}) \right]\,.
\end{array}
\end{equation}
Unfortunately, this structure is inconvenient because it mixes
different bin bounds and prevents a recursive computation.
However, we can try to go further and, assuming that the bin width is
small enough, we can expand $\mathcal{P}$ is the following ways:
\begin{equation}
\begin{array}{l}
\displaystyle\mathcal{P}\left(\frac{q_{T,\rm max}+q_{T,\rm
    min}}2\right)= \mathcal{P}\left(q_{T,\rm min}+\Delta q_T\right) =
  \mathcal{P}\left(q_{T,\rm min}\right) + \mathcal{P}'\left(q_{T,\rm
  min}\right)\Delta q_T +\mathcal{O}\left(\Delta q_T^2\right)\,,\\
\\
\displaystyle\mathcal{P}\left(\frac{q_{T,\rm max}+q_{T,\rm
    min}}2\right)= \mathcal{P}\left(q_{T,\rm max}-\Delta q_T\right) =
  \mathcal{P}\left(q_{T,\rm max}\right) - \mathcal{P}'\left(q_{T,\rm
  max}\right)\Delta q_T +\mathcal{O}\left(\Delta q_T^2\right)\,,
\end{array}
\end{equation}
with:
\begin{equation}\label{eq:halfqTinterval}
\Delta q_T = \frac{q_{T,\rm max}- q_{T,\rm min}}2\,.
\end{equation}
Therefore:
\begin{equation}\label{eq:lastexpP}
\begin{array}{rcl}
  \displaystyle  b\int_{q_{T,\rm min}}^{q_{T,\rm
  max}} dq_T\, q_T J_0(bq_T) \mathcal{P}(q_T)&\simeq&\displaystyle
                                                      q_{T,\rm
                                                      max}
                                                      J_1(bq_{T,\rm
                                                      max})\left[
                                                      \mathcal{P}\left(q_{T,\rm
                                                      max}\right)
                                                      - 
                                                      \mathcal{P}'\left(q_{T,\rm
                                                      max}\right)\Delta
                                                      q_T\right]\\
\\
&-&\displaystyle q_{T,\rm
                                                      min}
                                                      J_1(bq_{T,\rm
                                                      min})\left[
                                                      \mathcal{P}\left(q_{T,\rm
                                                      min}\right)
                                                      +
                                                      \mathcal{P}'\left(q_{T,\rm
                                                      min}\right)\Delta
                                                      q_T\right]\,.
\end{array}
\end{equation}
The advantage of this formula as compared to Eq.~(\ref{eq:intbyparts})
is that each single term depends on one single bin-bound in $q_T$
rather than on a combination of two consecutive bounds. Therefore, in
the presence of kinematic cuts, the actual form of the primitive
function $K$ defined in Eq.~(\ref{eq:primitive}) and given explicitly
in Eq.~(\ref{eq:Kexplicit}) is:
\begin{equation}\label{eq:KexplicitCuts}
\begin{array}{l}
 \displaystyle K(Q,y,q_T) =
  \frac{8\pi\alpha^2q_T}{9 Q^3} H(Q,\mu)
  \left[\mathcal{P}\left(Q,y,q_{T}\right) \pm
  \mathcal{P}'\left(Q,y,q_{T}\right)\Delta q_T\right]\\
\\
\displaystyle \times
  \int_0^\infty db\, J_1(bq_T) \sum_q C_q(Q)\overline{F}_q(x_1,b;\mu,\zeta) \overline{F}_{\bar{q}}(x_2,b;\mu,\zeta) f_{\rm NP}(x_1,b,\zeta)
  f_{\rm NP}(x_2,b,\zeta)\,,
\end{array}
\end{equation}
where I have explicitly reinstated the dependence of the function
$\mathcal{P}$ and its derivative with respect to $q_T$,
$\mathcal{P}'$, on $Q$ and $y$. In the square bracket in
Eq.~(\ref{eq:KexplicitCuts}), the minus sign applies when $q_T$ is the
upper bound of the bin and the plus sign when it is the lower bound
(see Eq.~(\ref{eq:lastexpP})). As discussed below, when integrating
over bins in $Q$ and $y$, one should also integrate the functions
$\mathcal{P}$ and $\mathcal{P}'$. However, we will argue that, in the
interpolation procedure discussed below, these functions can be
extracted from the integrals in $Q$ and $y$ in a proper manner in such
a way to avoid computing the expensive function $\mathcal{P}$ many
times and, moreover, simplify enormously the structure of the
resulting interpolation tables.

\subsection{On the position of the peak of the $q_T$ distribution}

It is interesting at this point to take a short detour to discuss the
position of the peak on the distribution in $q_T$ of the cross section
in Eq.~(\ref{eq:crosssection}). The peak can be located by setting the
derivative in $q_T$ of the cross section equal to zero. To do so, we
use another property of Bessel's functions:
\begin{equation}
\frac{dJ_0(x)}{dx} = -J_1(x)\,.
\end{equation}
Using this relation, it is easy to see that:
\begin{equation}
\begin{array}{l}
\displaystyle 0 = \frac{d}{dq_T}  \left[\frac{d\sigma}{dQ dy dq_T}\right]
  =\\
\\
\displaystyle  \frac{8\pi\alpha^2}{9 Q^3} H(Q,\mu) 
  \int_0^\infty db\,b \left[J_0(bq_T) -bq_TJ_1(bq_T)\right] 
\sum_q C_q(Q)\overline{F}_q(x_1,b_*(b);\mu,\zeta)
  \overline{F}_{\bar{q}}(x_2,b_*(b);\mu,\zeta)\\
\\
\displaystyle \times f_{\rm NP}(x_1,b,\zeta)
  f_{\rm NP}(x_2,b,\zeta)\,,
\end{array}
\end{equation}
that is equivalent to require that:
\begin{equation}
  \int_0^\infty db\,b \left[J_0(bq_T) -bq_TJ_1(bq_T)\right] 
  \sum_q C_q(Q)\overline{F}_q(x_1,b_*(b);\mu,\zeta) \overline{F}_{\bar{q}}(x_2,b_*(b);\mu,\zeta) f_{\rm NP}(x_1,b,\zeta)
  f_{\rm NP}(x_2,b,\zeta) = 0\,.
\end{equation}
The integral above can be solved numerically using the technique
discussed above and the value of $q_T$ that satisfies this equation
represents the position of the peak of the $q_T$ distribution.

\subsection{Integrating over $Q$ and $y$}\label{sec:QyInt}

As a final step, we need to perform the integrals over $Q$ and $y$
defined in Eq.~(\ref{eq:Intcrosssection}). To compute these integrals
we can only rely on numerical methods. Having reduced the integration
in $q_T$ to the difference of the two terms in the r.h.s. of
Eq.~(\ref{eq:primitive})(\footnote{For the moment we ignore the
  complication introduced by the presence of cuts on the final state
  discussed in Sect.~\ref{sec:kincuts}. We will come back on this
  issue at the end of the section.}), we can concentrate on
integrating the function $K$ over $Q$ and $y$ for a fixed value of
$q_T$:
\begin{equation}
\widetilde{K}(q_T)=\int_{Q_{\rm min}}^{Q_{\rm max}}dQ \int_{y_{\rm
    min}}^{y_{\rm max}}dy\,K(Q,y,q_T)\,,
\end{equation}
such that:
\begin{equation}
  \widetilde{\sigma} = \widetilde{K} (q_{T,\rm max})- \widetilde{K} (q_{T,\rm min})\,.
\end{equation}
To this purpose, it is convenient to make explicit the dependence of
$x_1$ and $x_2$ on $Q$ and $y$ using Eq.~(\ref{eq:Bjorkenx12}). In
addition, for the sake of simplicity we will identify the scales $\mu$
and $\sqrt{\zeta}$ with $Q$ (possible scale variations can be easily
reinstated at a later stage) and thus drop one of the arguments from
the TMD distributions $\overline{F}$ and from the hard factor $H$.
This yields:
\begin{equation}\label{eq:finalintegral}
\begin{array}{rcl}
\displaystyle  \widetilde{K}(q_T) &=& \displaystyle \frac{8\pi q_T}{9} \int_0^\infty db\, J_1(bq_T)
  \int_{Q_{\rm min}}^{Q_{\rm max}}
  dQ \int_{e^{y_{\rm
    min}}}^{e^{y_{\rm max}}}\frac{d\xi}{\xi}\\
\\
&\times& \displaystyle 
                         \frac{1}{Q^3} \alpha^2(Q) H(Q)\sum_q C_q(Q)\overline{F}_q\left(\frac{Q}{\sqrt{s}}\xi,b_*(b);Q\right)
                         \overline{F}_{\bar{q}}\left(\frac{Q}{\sqrt{s}}\frac1{\xi},b_*(b);Q\right) \\
\\
&\times& \displaystyle f_{\rm NP}\left(\frac{Q}{\sqrt{s}}\xi,b;Q\right)
  f_{\rm NP}\left(\frac{Q}{\sqrt{s}}\frac1{\xi},b;Q\right)\,,
\end{array}
\end{equation}
where we have performed the change of variable $e^{y} = \xi$. Now we
define one grid in $\xi$, $\{\xi_\alpha\}$ with
$\alpha=0,\dots,N_\xi$, and one grid in $Q$, $\{Q_\tau\}$ with
$\tau=0,\dots,N_Q$, each of which with a set of interpolating
functions $\mathcal{I}$ associated. In addition, the grids are such
that: $\xi_0 = e^{y_{\rm min}}$ and $\xi_{N_\xi} = e^{y_{\rm max}}$,
and $Q_0 = Q_{\rm min}$ and $Q_{N_Q} = Q_{\rm max}$. More details on
the interpolation procedure are presented in
Appendix~\ref{app:LagrangeInterpolation}. This allows us to interpolate
the pair of functions $f_{\rm NP}$ in Eq.~(\ref{eq:finalintegral}) for
generic values of $\xi$ and $Q$ as:
\begin{equation}\label{eq:interpolation}
f_{\rm NP}\left(\frac{Q}{\sqrt{s}}\xi,b;Q\right) f_{\rm NP}\left(\frac{Q}{\sqrt{s}}\frac1{\xi},b;Q\right) \simeq \sum_{\alpha=0}^{N_\xi}\sum_{\tau=0}^{N_Q}\mathcal{I}_\alpha(\xi)\mathcal{I}_\tau(Q) f_{\rm NP}\left(\frac{Q_\tau}{\sqrt{s}}\xi_\alpha,b;Q_\tau\right) f_{\rm NP}\left(\frac{Q_\tau}{\sqrt{s}}\frac1{\xi_\alpha},b;Q_\tau\right)\,.
\end{equation}
Plugging the equation above into Eq.~(\ref{eq:finalintegral}) we
obtain:
\begin{equation}
\begin{array}{rcl}
\displaystyle  \widetilde{K}(q_T) &\simeq& \displaystyle \frac{8\pi q_T}{9} \int_0^\infty db\, J_1(bq_T)
  \sum_{\tau=0}^{N_Q}\sum_{\alpha=0}^{N_\xi}\Bigg[\int_{Q_{\rm min}}^{Q_{\rm max}}dQ\,\mathcal{I}_\tau(Q)\, 
  \frac{1}{Q^3} \alpha^2(Q) H(Q) 
  \\
\\
&\times& \displaystyle 
                         \int_{e^{y_{\rm
    min}}}^{e^{y_{\rm max}}}d\xi\,\mathcal{I}_\alpha(\xi)\,\frac{1}{\xi} \sum_q C_q(Q)\overline{F}_q\left(\frac{Q}{\sqrt{s}}\xi,b_*(b);Q\right)
                         \overline{F}_{\bar{q}}\left(\frac{Q}{\sqrt{s}}\frac1{\xi},b_*(b);Q\right)\Bigg] \\
\\
&\times& \displaystyle f_{\rm NP}\left(\frac{Q_\tau}{\sqrt{s}}\xi_\alpha,b;Q_\tau\right) f_{\rm NP}\left(\frac{Q_\tau}{\sqrt{s}}\frac1{\xi_\alpha},b;Q_\tau\right)\,.
\end{array}
\end{equation}
Finally, the integration over $b$ can be performed using the Ogata
quadrature as discussed above, so that:
\begin{equation}
\begin{array}{rcl}
\displaystyle  \widetilde{K}(q_T) &\simeq& \displaystyle \sum_{n=1}^N
  \sum_{\tau=0}^{N_Q}\sum_{\alpha=0}^{N_\xi}\Bigg[\frac{8\pi}{9} w_n^{(1)}\int_{Q_{\rm min}}^{Q_{\rm max}}dQ\,\mathcal{I}_\tau(Q)\, 
  \frac{1}{Q^3} \alpha^2(Q) H(Q) 
\\
\\
&\times& \displaystyle 
                         \int_{e^{y_{\rm
    min}}}^{e^{y_{\rm max}}}d\xi\,\mathcal{I}_\alpha(\xi)\,\frac{1}{\xi} \sum_q C_q(Q)\overline{F}_q\left(\frac{Q}{\sqrt{s}}\xi,b_*\left(\frac{z_n}{q_T}\right);Q\right)
                         \overline{F}_{\bar{q}}\left(\frac{Q}{\sqrt{s}}\frac1{\xi},b_*\left(\frac{z_n}{q_T}\right);Q\right)\Bigg] \\
\\
&\times& \displaystyle f_{\rm NP}\left(\frac{Q_\tau}{\sqrt{s}}\xi_\alpha,\frac{z_n}{q_T};Q_\tau\right) f_{\rm NP}\left(\frac{Q_\tau}{\sqrt{s}}\frac1{\xi_\alpha},\frac{z_n}{q_T};Q_\tau\right)\,.
\end{array}
\end{equation}
In conclusion, if we define:
\begin{equation}\label{eq:weights}
\begin{array}{rcl}
  \displaystyle  W_{n\tau\alpha}(q_T) & \equiv & \displaystyle w_n^{(1)}\frac{8\pi}{9} \int_{Q_{\rm min}}^{Q_{\rm max}}dQ\,\mathcal{I}_\tau(Q)\, 
                                            \frac{\alpha^2(Q)}{Q^3} H(Q) 
                                            \\
  \\
                                 &\times& \displaystyle 
                                          \int_{e^{y_{\rm
                                          min}}}^{e^{y_{\rm max}}}d\xi\,\mathcal{I}_\alpha(\xi)\,\frac{1}{\xi} \sum_q C_q(Q)\overline{F}_q\left(\frac{Q}{\sqrt{s}}\xi,b_*\left(\frac{z_n}{q_T}\right);Q\right)
                                          \overline{F}_{\bar{q}}\left(\frac{Q}{\sqrt{s}}\frac1{\xi},b_*\left(\frac{z_n}{q_T}\right);Q\right)\,,
\end{array}
\end{equation}
the quantity $\widetilde{K}(q_T)$ can be computed as:
\begin{equation}\label{eq:finalinterpolated}
\widetilde{K}(q_T) \simeq \sum_{n=1}^N
  \sum_{\tau=0}^{N_Q}\sum_{\alpha=0}^{N_\xi} W_{n\tau\alpha}(q_T) f_{\rm NP}\left(\frac{Q_\tau}{\sqrt{s}}\xi_\alpha,\frac{z_n}{q_T};Q_\tau\right) f_{\rm NP}\left(\frac{Q_\tau}{\sqrt{s}}\frac1{\xi_\alpha},\frac{z_n}{q_T};Q_\tau\right)\,.
\end{equation}
The advantage of Eq.~(\ref{eq:finalinterpolated}) is that the weights
$W_{n\alpha\tau}$, that clearly depend on $q_T$ but also on the
intervals $[Q_{\rm min}:Q_{\rm max}]$ and $[y_{\rm min}:y_{\rm max}]$,
can be precomputed once and for all for each of the experimental
points included in a fit and used to determine the function
$f_{\rm NP}$.  This provides a fast tool for the computation of
predictions that makes the extraction of the non-perturbative part of
the TMDs much easier.

It is now time to discuss how the weights defined in
Eq.~(\ref{eq:weights}) are affected by the presence of cuts as
discussed in Sect.~\ref{sec:kincuts}. In principle, the function
between square brackets in Eq.~(\ref{eq:KexplicitCuts}) should be
inside the integrals in Eq.~(\ref{eq:weights}) and integrated over the
variable $Q$ and $\xi=e^y$. However, this turns out to be numerically
problematic because the phase-space-reduction function $\mathcal{P}$
is expensive to compute. On top of this, the fact that the factor
between square brackets in Eq.~(\ref{eq:KexplicitCuts}) depends on
whether $q_T$ is a lower or an upper integration bound would lead to a
duplication of the weights to compute. In order to simplify the
computation, we assume that the function $\mathcal{P}$ and its
derivative $\mathcal{P}'$ are slowly varying functions of $Q$ and $y$
over the typical grid interval of the grids in $Q$ and $\xi$. In
addition, the interpolating functions $\mathcal{I}_\tau(Q)$ and
$\mathcal{I}_\alpha(\xi)$ are strongly peaked at $Q_\tau$ and
$\xi_\alpha$, respectively. These considerations allow us to avoid
integrating explicitly $\mathcal{P}$ and $\mathcal{P}'$ over $Q$ and
$\xi$ and to replace the weights in Eq.~(\ref{eq:weights}) with:
\begin{equation}\label{eq:weightswithcuts}
  \displaystyle  W_{n\tau\alpha}(q_T) \rightarrow \left[\mathcal{P}\left(Q_\tau,\ln(\xi_\alpha),q_{T}\right) \pm
  \mathcal{P}'\left(Q_\tau,\ln(\xi_\alpha),q_{T}\right)\Delta q_T\right] W_{n\tau\alpha}(q_T)\,.
\end{equation}
At the end of the day, the only additional information required to
implement cuts on the final state is the value of the
phase-space-reduction function $\mathcal{P}$ and its derivative
$\mathcal{P}'$ on all points of the bidimensional grid in $Q$ and
$\xi$ for all $q_T$ bin bounds. Eq.~(\ref{eq:weightswithcuts}) will
then allow one to use the weights computed over the full phase space.
We will check the accuracy of this procedure by comparing it to the
explicit integration.

\subsection{Cross section differential in $x_F$}

In some cases, the Drell-Yan differential cross section may be
presented as differential in the invariant mass of the lepton pair $Q$
and, instead of the rapidity $y$, of the Feynman variable $x_F$
defined as:
\begin{equation}
  x_F = 
  \frac{Q}{\sqrt{s}}\left(e^{y} - e^{-y}\right) =
  \frac{2Q}{\sqrt{s}}\sinh y = x_1-x_2\,,
\end{equation}
so that:
\begin{equation}
\frac{dx_F}{dy} = \frac{2Q}{\sqrt{s}}\cosh y=x_1+x_2\,.
\end{equation}
Therefore:
\begin{equation}
  \frac{d\sigma}{dQ dx_F dq_T} =
  \frac{dy}{dx_F}\frac{d\sigma}{dQ dy dq_T}=
\frac{\sqrt{s}}{2Q\cosh y}\frac{d\sigma}{dQ dy dq_T}=\frac1{x_1+x_2}\frac{d\sigma}{dQ dy dq_T}
\end{equation}
with:
\begin{equation}
  y(x_F,Q) =
  \sinh^{-1}\left(\frac{x_F\sqrt{s}}{2Q}\right) =
  \ln\left[\frac{\sqrt{s}}{2Q}\left(x_F+\sqrt{x_F^2 + \frac{4Q^2}{s}}\right)\right]\,,
\end{equation}
so that:
\begin{equation}\label{eq:x12ofxFQ}
x_1 = \frac12\left(x_F+\sqrt{x_F^2 +
    \frac{4Q^2}{s}}\right)\quad\mbox{and}\quad x_2 = \frac{Q^2}{sx_1}\,.
\end{equation}
Therefore, we can compute the integral:
\begin{equation}
\widetilde{I}(q_T)=\int_{Q_{\rm min}}^{Q_{\rm max}}dQ \int_{x_{F,\rm
    min}}^{x_{F,\rm max}}dx_F\,I(Q,x_F,q_T)\,,
\end{equation}
where $I$ is the primitive in $q_T$ of the cross section differential
in $x_F$:
\begin{equation}
I(Q,x_F,q_T) = \int dq_T\left[\frac{d\sigma}{dQ dx_F dq_T}\right]\,,
\end{equation}
following the same steps of Sect.~\ref{sec:QyInt}. This leads to:
\begin{equation}
\begin{array}{rcl}
\displaystyle  \widetilde{I}(q_T) &\simeq& \displaystyle \sum_{n=1}^N
  \sum_{\tau=0}^{N_Q}\sum_{\alpha=0}^{N_x}\overline{W}_{n\tau\alpha}(q_T) f_{\rm NP}\left(x_{1,\alpha\tau},\frac{z_n}{q_T};Q_\tau\right) f_{\rm NP}\left(x_{2,\alpha\tau},\frac{z_n}{q_T};Q_\tau\right)\,,
\end{array}
\end{equation}
with:
\begin{equation}\label{eq:xFtens}
\begin{array}{rcl}
\displaystyle  \overline{W}_{n\tau\alpha}(q_T) &\equiv& \displaystyle w_n^{(1)}\frac{8\pi}{9} \int_{Q_{\rm min}}^{Q_{\rm max}}dQ\,\mathcal{I}_\tau(Q)\, 
  \frac{1}{Q^3} \alpha^2(Q) H(Q) 
\\
\\
&\times& \displaystyle 
                         \int_{x_{F,\rm
    min}}^{x_{F,\rm max}}dx_F\,\mathcal{I}_\alpha(x_F)\,\frac{1}{x_1+x_2} \sum_q C_q(Q)\overline{F}_q\left(x_1,b_*\left(\frac{z_n}{q_T}\right);Q\right)
                         \overline{F}_{\bar{q}}\left(x_2,b_*\left(\frac{z_n}{q_T}\right);Q\right)\,,
\end{array}
\end{equation}
where $x_1$ and $x_2$ are functions of $x_F$ and $Q$ through
Eq.~(\ref{eq:x12ofxFQ}). In addition, we have defined a grid in $x_F$,
$\{x_{F,\alpha}\}$ with $\alpha = 0,\dots,N_x$, that allowed us to
define $x_{1(2),\alpha\tau}\equiv x_{1(2)}(x_{F,\alpha},Q_\tau)$.

\subsection{Flavour dependence}

It may be advantageous to introduce a flavour dependence of the
non-perturbative contributions to TMDs. This can be easily done by
observing that the tensor $W_{n\tau\alpha}$ defined in
Eq.~(\ref{eq:weights}) can be decomposed as\footnote{The same
  procedure applies to the tensor $\overline{W}_{n\tau\alpha}$ defined
in Eq.~(\ref{eq:xFtens}).}:
\begin{equation}
W_{n\tau\alpha}(q_T) = \sum_q W_{n\tau\alpha}^{(q)} (q_T)\,,
\end{equation}
with:
\begin{equation}\label{eq:weightsfl}
\begin{array}{rcl}
  \displaystyle  W_{n\tau\alpha}^{(q)}(q_T) & \equiv & \displaystyle w_n^{(1)}\frac{8\pi}{9} \int_{Q_{\rm min}}^{Q_{\rm max}}dQ\,\mathcal{I}_\tau(Q)\, 
                                            \frac{\alpha^2(Q)}{Q^3} H(Q) C_q(Q)
                                            \\
  \\
                                 &\times& \displaystyle 
                                          \int_{e^{y_{\rm
                                          min}}}^{e^{y_{\rm max}}}d\xi\,\mathcal{I}_\alpha(\xi)\,\frac{1}{\xi} \overline{F}_q\left(\frac{Q}{\sqrt{s}}\xi,b_*\left(\frac{z_n}{q_T}\right);Q\right)
                                          \overline{F}_{\bar{q}}\left(\frac{Q}{\sqrt{s}}\frac1{\xi},b_*\left(\frac{z_n}{q_T}\right);Q\right)\,.
\end{array}
\end{equation}
This allows for an independent parameterisation of the
non-perturbative contribution such that
Eq.~(\ref{eq:finalinterpolated}) can be written as:
\begin{equation}\label{eq:finalinterpolatedfl}
\widetilde{K}(q_T) \simeq \sum_q\sum_{n=1}^N
  \sum_{\tau=0}^{N_Q}\sum_{\alpha=0}^{N_\xi} W_{n\tau\alpha}^{(q)}(q_T) f_{\rm NP}^{(q)}\left(\frac{Q_\tau}{\sqrt{s}}\xi_\alpha,\frac{z_n}{q_T};Q_\tau\right) f_{\rm NP}^{(q)}\left(\frac{Q_\tau}{\sqrt{s}}\frac1{\xi_\alpha},\frac{z_n}{q_T};Q_\tau\right)\,,
\end{equation}
where $f_{\rm NP}^{(q)}$ parametrises the non-perturbative component
of the TMD with flavour $q$.

\subsection{Gradient with respect to the free parameters}

A very appealing implication of the computation of cross section in
terms of precomputed table as in Eqs.~(\ref{eq:finalinterpolated})
and~(\ref{eq:finalinterpolatedfl}) is the fact that it exposes the
free parameters of the non-perturbative functions. To be more
specific, the non-perturbative function $f_{\rm NP}$, on top of being
a function of $x$, $b$, and $\zeta$, depends parameterically on a set
of $N_p$ parameters $\{\theta_k\}$, $k=1,\dots,N_p$, that are
typically determined by fits to data, in other words:
\begin{equation}
f_{\rm NP}\equiv f_{\rm NP}\left(x,b,\zeta;\{\theta_k\}\right)\,.
\end{equation}
Now, when performing a fit, it is very useful to be able to compute
the derivative of the figure of merit (usually the $\chi^2$) with
respect to the parameters to be determined. In turn, this immediately
implies being able to compute the derivative of the
observables. Referring to Eq.~(\ref{eq:finalinterpolated}), the
relevant quantity is:
\begin{equation}
\frac{d\widetilde{K}}{d\theta_k}=
\sum_{n=1}^N
  \sum_{\tau=0}^{N_Q}\sum_{\alpha=0}^{N_\xi} W_{n\tau\alpha}(q_T) \left[\frac{d f_{\rm NP}^{(1)}}{d\theta_k} f_{\rm NP}^{(2)}+f_{\rm NP}^{(1)}\frac{d f_{\rm NP}^{(2)}}{d\theta_k} \right]\,,
\end{equation}
where $f_{\rm NP}^{(1)}$ and $f_{\rm NP}^{(2)}$ refer to the
non-perturbative function $f_{\rm NP}$ computed in $x_1$ and $x_2$,
respectively. It is thus clear that the derivatives w.r.t. the free
parameters penetrates the observable. Since in most cases the
derivative of $f_{\rm NP}$ can be computed analytically, this allows
one to compute the gradient of the figure of merit analytically. This
potentially makes any fit much simpler.

\subsection{Narrow-width approximation}

A possible alternative to the numerical integration in $Q$ when the
integration region includes the $Z$-peak region is the so-called
narrow-width approximation (NWA). In the NWA one assumes that the
width of the $Z$ boson, $\Gamma_Z$, is much smaller than its mass,
$M_Z$. This way one can approximate the peaked behaviour of the
couplings $C_q(Q)$ around $Q=M_Z$ with a $\delta$-function,
\textit{i.e.}  $C_q(Q)\sim \delta(Q^2-M_Z^2)$. Therefore, the
integration over $Q$ can be done analytically. The exact structure of
the electroweak couplings is the following:
\begin{equation}\label{eq:fullcoup}
C_q(Q) = e_q^2 - 2 e_q V_q V_e \chi_1(Q) + (V_e^2 + A_e^2)(V_q^2 + A_q^2)\chi_2(Q)\,,
\end{equation}
with:
\begin{equation}
\begin{array}{l}
\displaystyle \chi_1(Q) = \frac{1}{4 \sin^2\theta_W \cos^2\theta_W } \frac{Q^2 ( Q^2 -  M_Z^2 )}{ (Q^2 - M_Z^2)^2 + M_Z^2 \Gamma_Z^2} \,,\\
\displaystyle \chi_2(Q) = \frac{1}{16 \sin^4\theta_W\cos^4\theta_W} \frac{Q^4}{ (Q^2 - M_Z^2)^2 + M_Z^2 \Gamma_Z^2} \,.
\end{array}
\end{equation}
In the limit $\Gamma_Z/M_Z\rightarrow 0$, the leading contribution to
the coupling in Eq.~(\ref{eq:fullcoup}) comes from the region
$Q\simeq M_Z$ and is that proportional to $\chi_2$:
\begin{equation}\label{eq:partlead}
C_q(Q) \simeq (V_e^2 + A_e^2)(V_q^2 + A_q^2)\chi_2(Q)\,,\quad Q\simeq M_Z\,.
\end{equation}
In addition, in this limit one can show that:
\begin{equation}\label{eq:breitwigner}
\frac{1}{ (Q^2 - M_Z^2)^2 + M_Z^2 \Gamma_Z^2}\rightarrow
\frac{\pi}{M_Z\Gamma_Z}\delta(Q^2-M_Z^2) = \frac{\pi}{2M_Z^2\Gamma_Z}\delta(Q-M_Z)\,.
\end{equation}
Therefore, considering that:
\begin{equation}
\Gamma_Z = \frac{\alpha M_Z}{\sin^2\theta_W \cos^2\theta_W}\,,
\end{equation}
the electroweak couplings in the NWA have the following form:
\begin{equation}\label{eq:partlead}
  C_q(Q) \simeq \frac{\pi M_Z (V_e^2 + A_e^2)(V_q^2 + A_q^2) }{32 \alpha
    \sin^2\theta_W\cos^2\theta_W} \delta(Q-M_Z)=\widetilde{C}_q(Q) \delta(Q-M_Z)\,.
\end{equation}
Therefore, using Eq.~(\ref{eq:partlead}) the integral of the cross
section over $Q$ under the condition that
$Q_{\rm min}<M_Z<Q_{\rm max}$ has the consequence of adjusting the
couplings and of setting $Q=M_Z$ in the computation. This yields:
\begin{equation}
\int_{Q_{\rm min}}^{Q_{\rm max}}dQ\,\frac{d\sigma}{dQ dy dq_T} =
 \frac{16\pi\alpha^2q_T}{9 M_Z^3} H(M_Z,M_Z) \sum_q \widetilde{C}_q(M_Z)
  I_{q\bar{q}}(x_1,x_2,q_T;M_Z,M_Z^2)\,,
\end{equation}
where we are also assuming that $\mu=\sqrt{\zeta}=M_Z$. As a final
step, one may want to let the $Z$ boson decay into leptons. At leading
order in the EW sector and assuming an equal decay rate for electrons,
muons, and tauons, this can be done by multiplying the cross section
above by three times the branching ratio for the $Z$ decaying into any
pair of leptons, $3\mbox{Br}(Z\rightarrow \ell^+\ell^-)$.


\newpage
\appendix

\section{Ogata quadrature}\label{app:OgataQuadrature}

In this section we limit ourselves to write the formulas for the
computation of the unscaled coordinates $z_n^{(\nu)}$ and weights
$w_n^{(\nu)}$ required to compute the following integral:
\begin{equation}\label{eq:OgataQuadMast}
I_\nu(q_T)=\int_0^\infty db J_\nu(bq_T) f\left(b\right) =
\frac1{q_T}\int_0^\infty d\bar{b} J_\nu(\bar{b})
f\left(\frac{\bar{b}}{q_T}\right) \simeq
\frac{1}{q_T}\sum_{n=1}^\infty
w_n^{(\nu)}f\left(\frac{z_n^{(\nu)}}{q_T}\right)\quad \nu =0,1,\dots\,,
\end{equation}
using the Ogata-quadrature algorithm. More details can be found in
Ref.~\cite{Ogata:quadrature}. There relevant formulas are:
\begin{equation}
\begin{array}{l}
\displaystyle z_n^{(\nu)} = \frac{\pi}{h}  \psi\left(\frac{h\xi_{\nu
  n}}{\pi}\right)\,,\\
\\
\displaystyle w_n^{(\nu)}  = \pi\frac{Y_\nu(\xi_{\nu
  n})}{J_{\nu+1}(\xi_{\nu n})}  J_\nu(z_n^{(\nu)})  \psi'\left(\frac{h\xi_{\nu
  n}}{\pi}\right)\,.
\end{array}
\end{equation}
where:
\begin{itemize}
\item $h$ is a free parameter of the algorithm that has to be
  typically small (we choose $h = 10^{-3}$),
\item $\xi_{\nu n}$ are the zero's of $J_\nu$, \textit{i.e.}
  $J_\nu(\xi_{\nu n}) = 0$ $\forall\, n$,
\item $J_\nu$ and $Y_\nu$ are the Bessel functions of first and second
  kind, respectively, of degree $\nu$,
\item $\psi$ is the following function:
\begin{equation}
\psi(t) = t\tanh\left(\frac{\pi}{2}\sinh t\right)
\end{equation}
and its derivative:
\begin{equation}
\psi'(t) =  \frac{\pi t \cosh t + \sinh( \pi \sinh t ) }{1 +
  \cosh( \pi \sinh t  ) }\,.
\end{equation}
\end{itemize}

\section{Lagrange interpolation}\label{app:LagrangeInterpolation}

Just for the record, it is useful to derive a general expression for
the Lagrange interpolating functions $\mathcal{I}$ introduced in
Eq.~(\ref{eq:interpolation}) and used to interpolate the
non-perturbative functions $f_{\rm NP}$. More, importantly, we need to
understand how these functions behave upon integration.

Suppose one wants to interpolate the test function $g$ in the point
$x$ using a set of Lagrange polynomials of degree $k$. This requires a
subset of $k+1$ consecutive points on an interpolation grid, say
$\{x_{\alpha},\dots,x_{\alpha+k}\}$. The relative position between the
point $x$ and the subset of points used for the interpolation is
arbitrary. It is convenient to choose the subset of points such that
$x_\alpha < x \leq x_{\alpha+k}$.\footnote{In fact, it is not even
  necessary to impose the constraint $x_\alpha < x \leq x_{\alpha+k}$.
  In case this relation is not fulfilled one usually refers to
  \textit{extrapolation} rather than \textit{interpolation}. If not
  necessary, this option is typically not convenient because it may
  lead to a substantial deterioration in the accuracy with which
  $g(x)$ is determined.}  However, the ambiguity remains because there
are $k$ possible choices according to whether
$x_\alpha < x \leq x_{\alpha+1}$, or
$x_{\alpha+1} < x \leq x_{\alpha+2}$, and so on.

In order to determine the exact form of the interpolation functions
$\mathcal{I}$, let us see how to derive
eq.~(\ref{eq:interpolation}). Using the standard Lagrange
interpolation procedure, we can approximate the function $g$ in $x$
as:
\begin{equation}\label{particularCase}
g(x) = \sum_{i=0}^k\ell_i^{(k)}(x)g(x_{\alpha+i})\,,
\end{equation}
where $\ell_i^{(k)}$ is the $i$-th Lagrange polynomial of degree $k$
which can be written as:
\begin{equation}\label{eq:LagPoly}
\ell_i^{(k)}(x) = \prod^{k}_{m=0,m\ne
i}\frac{x-x_{\alpha+m}}{x_{\alpha+i}-x_{\alpha+m}}\,.
\end{equation}
We now assume that:
\begin{equation}\label{eq:assumption1}
x_{\alpha} < x \leq x_{\alpha+1}\,,
\end{equation}
Eq.~(\ref{particularCase}) becomes:
\begin{equation}\label{particularCaseTheta}
  g(x) =
  \theta(x-x_{\alpha})\theta(x_{\alpha+1}-x)\sum_{i=0}^k
  g(x_{\alpha+i})\prod^{k}_{m=0,m\ne
    i}\frac{x-x_{\alpha+m}}{x_{\alpha+i}-x_{\alpha+m}}\,.
\end{equation}

In order to make Eq.~(\ref{particularCaseTheta}) valid for all values
of $\alpha$, one just has to sum over all $N_x$ intervals of the
\textit{global} interpolation grid $\{x_0,\dots,x_{N_x}\}$, that is:
\begin{equation}\label{generalCase}
  g(x) =
  \sum_{\alpha=0}^{N_x-1}\theta(x-x_{\alpha})\theta(x_{\alpha+1}-x)\sum_{i=0}^k
  g(x_{\alpha+i})\prod^{k}_{m=0,m\ne
    i}\frac{x-x_{\alpha+m}}{x_{\alpha+i}-x_{\alpha+m}}\,,
\end{equation}

Defining $\beta=\alpha+i$, we can rearrange the equation above as:
\begin{equation}\label{generalCase2}
  g(x) =
  \sum_{\beta=0}^{N_x+k-1}\mathcal{I}_\beta^{(k)}(x) g(x_{\beta})\,,
\end{equation}
that leads us to the definition of the interpolating functions:
\begin{equation}\label{eq:intfunc}
  \mathcal{I}_\beta^{(k)}(x) = \sum_{i=0,i\leq\beta}^k
  \theta(x-x_{\beta-i})\theta(x_{\beta-i+1}-x) \prod^{k}_{m=0,m\ne
    i}\frac{x-x_{\beta-i+m}}{x_{\beta}-x_{\beta-i+m}}\,,
\end{equation}
where the condition $i\leq\beta$ comes from the condition
$\alpha\geq 0$. It is important to observe that the sum in
Eq.~(\ref{generalCase2}) extends up to the $(N_x+k-1)$-th
node. Therefore, the original grid needs to be extended by $k-1$
nodes. However, the range of validity of the interpolation remains
that defined by the original grid, \textit{i.e.}
$x_0 \leq x \leq x_{N_x}$. 

When implementing this interpolation procedure, it is convenient to
realise that, typically, only a small number of terms in the sum in
Eq.~(\ref{generalCase2}) is different from zero. For any give value of
$x$, it is possible to determine the values of the index $\beta$ for
which the interpolating functions $\mathcal{I}_\beta^{(k)}$ are
different from zero, reducing (often dramatically) the amount of sums
required to carry out an interpolation. The range of $\beta$ is easily
determined by observing that in Eq.~(\ref{particularCaseTheta}) the
summation extends on the nodes between $x_\alpha$ and
$x_{\alpha+k}$. But since $\beta$ is defined like $\alpha+i$ this
exactly defines the range in $\beta$:
\begin{equation}
\alpha(x) \leq \beta \leq \alpha(x) + k\,,
\end{equation}
where the function $\alpha(x)$ is implicitly defined through
Eq.~(\ref{eq:assumption1}). Therefore, Eq.~(\ref{generalCase2})
becomes:
\begin{equation}\label{eq:limitedsum}
  g(x) =
  \sum_{\beta=\alpha(x)}^{\alpha(x)+k}\mathcal{I}_\beta^{(k)}(x) g(x_{\beta})\,,
\end{equation}

Finally, we notice that sometimes it may be required to integrate the
interpolating functions. In this case, it is very useful to use the
fact that the interpolation function $\mathcal{I}_\beta^{(k)}(x)$ is
different from zero only over a limited interval, specifically:
\begin{equation}\label{eq:limits}
\mathcal{I}_\beta^{(k)}(x) \neq 0\quad \Leftrightarrow\quad
x_{\beta-k}<x < x_{\beta+1}\,.
\end{equation}
This allows one to optimise the integration restricting the
integration region only to where the interpolating functions is
different from zero.

\subsection{Generalised interpolation}

In the rest of this document we will stick to the assumption in
Eq.~(\ref{eq:assumption1}). However, before going further, it is
interesting to generalise Eq.~(\ref{eq:assumption1}) to:
\begin{equation}\label{IntAssumptionGen}
  x_{\alpha+t} < x \leq
  x_{\alpha+t+1}\quad\mbox{with}\quad t = 0,\dots,k-1\,,
\end{equation}
such that the interpolation formula becomes:
\begin{equation}\label{MoreGeneralCase}
  g(x) =
  \sum_{\alpha=-t}^{N_x-t-1}\theta(x-x_{\alpha+t})\theta(x_{\alpha+t+1}-x)\sum_{i=0}^k
  g(x_{\alpha+i})\prod^{k}_{m=0,m\ne
    i}\frac{x-x_{\alpha+m}}{x_{\alpha+i}-x_{\alpha+m}}\,,
\end{equation}
that can be rearranged as:
\begin{equation}\label{generalCase3}
g(x) =
\sum_{\beta=-t}^{N_x+k-t-1}\mathcal{I}_{\beta,t}^{(k)}(x) g(x_{\beta})\,,
\end{equation}
with:
\begin{equation}\label{eq:generalisedintfuncs}
\mathcal{I}_{\beta,t}^{(k)}(x) = \sum_{i=0,i\leq\beta}^k
\theta(x-x_{\beta-i+t})\theta(x_{\beta-i+t+1}-x) \prod^{k}_{m=0,m\ne
i}\frac{x-x_{\beta-i+m}}{x_{\beta}-x_{\beta-i+m}}\,,
\end{equation}
being the ``generalised'' interpolation functions. We observe that the
support region of $\mathcal{I}_{\beta,t}^{(k)}$ is:
\begin{equation}
\mathcal{I}_{\beta,t}^{(k)}(x)\neq 0 \quad\Leftrightarrow\quad x_{\beta+t-k} < x < x_{\beta+t+1}\,,
\end{equation}
that generalises Eq.~(\ref{eq:limits}). The generalised interpolation
functions can be used to avoid interpolating over some particular grid
nodes. This turns out to be useful when interpolating non-smooth
functions or with discontinuities, such as PDFs or FFs as functions of
the factorisation scales in correspondence of the heavy-quark
thresholds.  More specifically, one can choose $t$ dynamically in such
a way that $\beta+t$ in Eq.~(\ref{eq:generalisedintfuncs}) never
corresponds to the heavy-quark thresholds node. This mechanism is
implemented in APFEL as follows. The interpolation grid is chosen to
have two nodes in correspondence of the threshold $x_T$, but slightly
displaced up and down by an ``infinitesimal'' amount $\epsilon$ to
keep them separate, that is:
\begin{equation}
\{x_0,\dots,x_{\alpha_t-1},x_{\alpha_t},\dots,x_{N_x}\}\quad\mbox{with}\quad x_{\alpha_t-1}=x_T-\epsilon\quad\mbox{and}\quad x_{\alpha_t}=x_T+\epsilon\,.
\end{equation}
The aim is then to avoid interpolating over the nodes $x_{\alpha_t-1}$
and $x_{\alpha_t}$. By default we assume $t=0$ in
Eq.~(\ref{eq:generalisedintfuncs}) so that we automatically reduce to
Eq.~(\ref{eq:intfunc}). In this situation, we are assuming
Eq.~(\ref{eq:assumption1}) where effectively the index $\alpha$ is
determined dynamically according to the values of $x$. Therefore, we
can effectively write:
\begin{equation}
x_{\alpha(x)} < x \leq x_{\alpha(x)+1}\,,
\end{equation}
which implicitly defines the function
$\alpha(x)$. Eq.~(\ref{particularCaseTheta}) then requires summing
over the $k+1$ nodes of the grid
$\{x_{\alpha(x)},\dots,x_{\alpha(x)+k}\}$. However, when the point $x$
approaches $x_T$ from below, the range
$\{x_{\alpha(x)},\dots,x_{\alpha(x)+k}\}$ may end up enclosing both
nodes $x_{\alpha_t-1}$ and $x_{\alpha_t}$. To avoid this, we promote
the index $t$ in Eq.~(\ref{IntAssumptionGen}) to a function of $x$
defined through the inequalities:
\begin{equation}
\left\{\begin{array}{l}
x< x_T\,,\\
\\
x_{\alpha_t-2} < x_{\alpha(x)-t(x)+k}\leq x_{\alpha_t-1}\,,
\end{array}\right.
\end{equation}
that translate into:
\begin{equation}
\left\{\begin{array}{l}
\alpha(x) \leq \alpha_t -2\,,\\
\\
\alpha_t-2 <  \alpha(x)-t(x)+k \leq \alpha_t-1\,.
\end{array}\right.
\end{equation}
Being all integers and imposing the unnecessary but convenient
constraint $t(x)\geq 0$, we find the final expression:
\begin{equation}\label{eq:tdef}
t(x) = \mbox{max}\left[\mbox{min}\left[\alpha(x),\alpha_t -2\right] -\alpha_t+k + 1, 0\right] \,,
\end{equation}
that also obeys:
\begin{equation}
0\leq t(x) \leq k - 1\,,
\end{equation}
as required. In addition, as in Eq.~(\ref{eq:limitedsum}), the
summation over $\beta$ in Eq.~(\ref{generalCase3}) can be restricted
to a range of $k+1$ nodes as:
\begin{equation}\label{generalCase4}
g(x) =
\sum_{\beta=\alpha(x)-t(x)}^{\alpha(x)-t(x)+k}\mathcal{I}_{\beta,t}^{(k)}(x) g(x_{\beta})\,.
\end{equation}

\subsection{Bi-dimensional interpolation}

Now suppose we want to compute the following integral:
\begin{equation}
I_1 = \int_{x_0}^{x_{N_x}}dx\,g(x)f(x)\,,
\end{equation}
where $f$ is a smooth function. Using Eqs.~(\ref{generalCase2})
and~(\ref{eq:limits}) we have that:
\begin{equation}
  I_1 = \sum_{\beta=0}^{N_x+k-1} W_\beta g(x_{\beta})\,,
\end{equation}
with:
\begin{equation}\label{eq:monodim}
W_\beta = \int_{x_{{\rm max}(0,\beta-k)}}^{x_{{\rm min}(N_x,\beta+1)}}dx \,\mathcal{I}_\beta^{(k)}(x)f(x)\,.
\end{equation}
The equation above can be easily generalised to a bidimensional
integral as:
\begin{equation}
I_2 = \int_{x_0}^{x_{N_x}}dx \int_{y_0}^{y_{N_y}}dy\,g(x,y)f(x,y) = \sum_{\alpha=0}^{N_x+k-1} \sum_{\beta=0}^{N_y+l-1} W_{\alpha\beta} g(x_{\alpha},y_{\beta})\,,
\end{equation}
with:
\begin{equation}\label{eq:bidim}
W_{\alpha\beta} = \int_{x_{{\rm max}(0,\alpha-k)}}^{x_{{\rm
      min}(N_x,\alpha+1)}}dx \int_{y_{{\rm max}(0,\beta-k)}}^{y_{{\rm
      min}(N_y,\beta+1)}}dy \,\mathcal{I}_\alpha^{(k)}(x)\,\mathcal{I}_\beta^{(l)}(y)\,f(x,y)\,.
\end{equation}
This formalism nicely applies to the integral in $Q$ and $\xi=e^{y}$
discussed above in Eq.~(\ref{eq:weights}). In view of a numerical
implementation, it is worth noticing that the functions $\mathcal{I}$
are piecewise. In particular, while these functions are continuous in
correspondence of the nodes of the grid, their first derivative is
not. As a consequence, the result of the numerical integrals in
Eqs.~(\ref{eq:monodim}) and~(\ref{eq:bidim}) may be inaccurate. To
overcome this problem, it is sufficient to split the integrals in
sub-integrals over the intervals delimited by two consecutive
nodes. Using Eq.~(\ref{eq:limits}), it is easy to see that, for an
interpolation of degree $k$, one needs to do $k+1$ integrals over the
intervals included between the $(\beta-k)$-th and the $(\beta+1)$-th
node.

\subsection{Derivative and integral of an interpolated function}

The simple form of the Lagrange polynomials allows, in some cases, for
the analytic handling of operations such has derivation and
integration of the interpolated functions. In this section we discuss
how derivation and integration can be carried out analytically
exploiting the properties of the Lagrange polynomials.

We start from Eq.~(\ref{particularCase}) and the main observation is
that the interpolating functions $\ell_i^{(k)}$ are solutions of the
following differential-equation system:
\begin{equation}\label{eq:diffeqlagpol}
\left\{
\begin{array}{l}
\displaystyle \frac{d\ell_i^{(k)}}{dx} = \left(\sum_{n=0 \atop n\neq
  i}^k\frac{1}{x-x_{\alpha+n}}\right) \ell_i^{(k)}(x)\\
\\
\ell_i^{(k)}(x_{\alpha+i}) = 1
\end{array}
\right.\,,
\end{equation}
whose solution is Eq.~(\ref{eq:LagPoly}). This allows us to compute the
derivative of the test function $g$ in Eq.~(\ref{eq:limitedsum}) only
knowing its values on the grid points as: 
\begin{equation}\label{DerGeneralCase2}
  \frac{dg}{dx} =
  \sum_{\beta=\alpha(x)}^{\alpha(x)+k}\mathcal{D}_\beta^{(k)}(x) g(x_{\beta})\,,
\end{equation}
where:
\begin{equation}\label{eq:derintfunc}
  \mathcal{D}_\beta^{(k)}(x) = \sum_{i=0}^{{\rm min}(k,\beta)}
  \theta(x-x_{\beta-i})\theta(x_{\beta-i+1}-x) \left(\sum_{n=0 \atop n\neq
  i}^k\frac1{x_\beta-x_{\beta-i+n}}\prod^{k}_{m=0\atop m\ne
    i,n}\frac{x-x_{\beta-i+m}}{x_{\beta}-x_{\beta-i+m}}\right)\,.
\end{equation}

Eq.~(\ref{eq:diffeqlagpol}) can also be used to compute integrals of
the function $g$. In particular, we want to compute the integral:
\begin{equation}\label{eq:IntegralInt}
I(a,b) = \int_a^b dy\,g(y)\,.
\end{equation}
Using Eq.~(\ref{eq:limitedsum}), we find that:
\begin{equation}
  I(a,b)=
  \int_a^b dy
  \sum_{\beta=\alpha(y)}^{\alpha(y)+k}\mathcal{I}_\beta^{(k)}(y)
  g(x_{\beta}) = \int_a^b dy\left[\mathcal{I}_{\alpha(y)}^{(k)}(y)
  g(x_{\alpha(y)})+\dots+\mathcal{I}_{\alpha(y)+k}^{(k)}(y)
  g(x_{\alpha(y)+k})\right]\,.
\end{equation}
The dependence on the integration variable $y$ of the index $\alpha$
complicates the solution of this integral. It is easy to derive a
close form for the function $\alpha(y)$:
\begin{equation}
\alpha(y) = -1 + \sum_{\beta = 0}^{N_x}\theta(y-x_\beta)\,,
\end{equation}
that (obviously) means that $\alpha(y)$ is constant on the separate
intervals $[x_0:x_1]$, $[x_1:x_2]$, and so on. This allows us to break
the integral above as follows:
\begin{equation}
\int_a^b dy \sum_{\beta=\alpha(y)}^{\alpha(y)+k}\mathcal{I}_\beta^{(k)}(y)
  g(x_{\beta})= \left[\int_a^{x_{\alpha(a)+1}}+ \sum_{\gamma=\alpha(a)+1}^{\alpha(b)-1}\int_{x_\gamma}^{x_{\gamma+1}}+\int_{x_{\alpha(b)}}^b\right]dy \sum_{\beta=\alpha(y)}^{\alpha(y)+k}\mathcal{I}_\beta^{(k)}(y)
  g(x_{\beta})\,,
\end{equation}
such that in each single integral the integrand has a constant value
of $\alpha$. The three terms above can be separately rearranged as:
\begin{equation}
\sum_{\beta=\alpha(a)}^{\alpha(a)+k}g(x_{\beta})\int_a^{x_{\alpha(a)+1}}dy\,\mathcal{I}_\beta^{(k)}(y)\,,
\end{equation}
\begin{equation}
\sum_{\gamma=\alpha(a)+1}^{\alpha(b)-1}\sum_{\beta=\gamma}^{\gamma+k}g(x_{\beta})\int_{x_\gamma}^{x_{\gamma+1}}dy\,\mathcal{I}_\beta^{(k)}(y)\,,
\end{equation}
\begin{equation}
\sum_{\beta=\alpha(b)}^{\alpha(b)+k}g(x_{\beta})\int_{x_{\alpha(b)}}^bdy\,
\mathcal{I}_\beta^{(k)}(y)\,,
\end{equation}
where we have also sude the fact that
$\alpha(x_\gamma)=\gamma$. Notice that this we managed to obtain
direct integrations of the interpolating functions
$\mathcal{I}_\beta^{(k)}$. Now we note that the three terms above span
the range of nodes $\beta\in[\alpha(a):\alpha(b)+k]$. Therefore, the
integral in Eq.~(\ref{eq:IntegralInt}) can be written as:
\begin{equation}\label{eq:integralT0}
  I(a,b) =
  \sum_{\beta=\alpha(a)}^{\alpha(b)+k}\mathcal{G}_\beta^{(k)}(a,b) g(x_{\beta})\,,
\end{equation}
with:
% \begin{equation}
% \mathcal{G}_\beta^{(k)}(a,b) = \int_a^bdy\,\mathcal{I}_\beta^{(k)}(y)\,.
% \end{equation}
% From Eq.~(\ref{eq:limits}), we know that the integrand
% $\mathcal{I}_\beta^{(k)}(y)$ is zero outside the interval
% $y\in [x_{\beta-k}:x_{\beta+1}]$. Assuming that $a\leq b$, there are a
% few possible configurations:
% \begin{itemize}
% \item $x_{\beta-k}\geq b$ or $x_{\beta+1}\leq a$: in these cases there is no
%   overlap between the support region of $\mathcal{I}_\beta^{(k)}$ and
%   the integration range. It follows that:
% \begin{equation}
% \mathcal{G}_\beta^{(k)}(a,b)=0\,.
% \end{equation}

% \item $x_{\beta-k}\geq a$ and $x_{\beta+1}\leq b$: in this case the
%   support region of $\mathcal{I}_\beta^{(k)}$ is entirely contained in
%   the integration range. Therefore:
% \begin{equation}
% \begin{array}{rcl}
% \displaystyle \mathcal{G}_\beta^{(k)}(a,b) =
%   \int_{x_{\beta-k}}^{x_{\beta+1}}dy\,\mathcal{I}_\beta^{(k)}(y)&=&\displaystyle
%                                                                     \sum_{i=0}^{{\rm
%                                                                     min}(k,\beta)}
%   \int_{x_{\beta-k}}^{x_{\beta+1}}dy\,\theta(y-x_{\beta-i})\theta(x_{\beta-i+1}-y)
%   \prod^{k}_{m=0\atop m\ne
%     i}\frac{y-x_{\beta-i+m}}{x_{\beta}-x_{\beta-i+m}}\\
% \\
% &=&\displaystyle \sum_{i=0}^{{\rm min}(k,\beta)}
%   \int_{x_{\beta-i}}^{x_{\beta-i+1}}dy
%   \prod^{k}_{m=0\atop m\ne
%     i}\frac{y-x_{\beta-i+m}}{x_{\beta}-x_{\beta-i+m}}
% \end{array}
% \end{equation}

% \item $x_{\beta-k}\geq a$ and $x_{\beta+1}> b$:
% \begin{equation}
% \mathcal{G}_\beta^{(k)}(a,b) = \int_{x_{\beta-k}}^{b}dy\,\mathcal{I}_\beta^{(k)}(y)=\sum_{i=0}^{{\rm min}(k,\beta)}\theta(b-x_{\beta-i})
%   \int_{x_{\beta-i}}^{{\rm min}(x_{\beta-i+1},b)}dy
%   \prod^{k}_{m=0\atop m\ne
%     i}\frac{y-x_{\beta-i+m}}{x_{\beta}-x_{\beta-i+m}}
% \end{equation}

% \item $x_{\beta-k}< a$ and $x_{\beta+1}\leq b$:
% \begin{equation}
% \mathcal{G}_\beta^{(k)}(a,b) = \int_{a}^{x_{\beta+1}}dy\,\mathcal{I}_\beta^{(k)}(y)=\sum_{i=0}^{{\rm min}(k,\beta)}
%   \theta(x_{\beta-i+1}-a)\int_{{\rm max}(x_{\beta-i},a)}^{x_{\beta-i+1}}dy
%   \prod^{k}_{m=0\atop m\ne
%     i}\frac{y-x_{\beta-i+m}}{x_{\beta}-x_{\beta-i+m}}
% \end{equation}

% \item $x_{\beta-k}< a$ and $x_{\beta+1}> b$: in this case the support
%   region of $\mathcal{I}_\beta^{(k)}$ contains the integration
%   range. Therefore:
% \begin{equation}
% \mathcal{G}_\beta^{(k)}(a,b) = \int_{a}^{b}dy\,\mathcal{I}_\beta^{(k)}(y) =\sum_{i=0}^{{\rm min}(k,\beta)}
%   \theta(b-x_{\beta-i})\theta(x_{\beta-i+1}-a)\int_{{\rm max}(x_{\beta-i},a)}^{{\rm min}(x_{\beta-i+1},b)}dy\prod^{k}_{m=0\atop m\ne
%     i}\frac{y-x_{\beta-i+m}}{x_{\beta}-x_{\beta-i+m}}\,.
% \end{equation}

% \end{itemize}

% \newpage

\begin{equation}
\begin{array}{rcl}
\displaystyle \mathcal{G}_\beta^{(k)}(a,b) &=& \displaystyle
                                               \int_{{\rm
                                               max}(a,x_{\beta-k})}^{{\rm
                                               min}(b,x_{\beta+1})}
                                               dy\,\mathcal{I}_\beta^{(k)}(y)\\
\\
&=&\displaystyle 
\sum_{i=0}^{{\rm min}(k,\beta)}
  \int_{{\rm max}(a,x_{\beta-k})}^{{\rm min}(b,x_{\beta+1})}dy\,\theta(y-x_{\beta-i})\theta(x_{\beta-i+1}-y)
  \prod^{k}_{m=0\atop m\ne
    i}\frac{y-x_{\beta-i+m}}{x_{\beta}-x_{\beta-i+m}}\,.
\end{array}
\end{equation}
Now, assuming that $a\leq b$, we can write the integral above as:
\begin{equation}
\int_{{\rm max}(a,x_{\beta-k})}^{{\rm min}(b,x_{\beta+1})} dy\,\theta(y-x_{\beta-i})\theta(x_{\beta-i+1}-y)\dots
=\theta(b-x_{\beta-i})\theta(x_{\beta-i+1}-a)\int_{{\rm max}(a,x_{\beta-i})}^{{\rm min}(b,x_{\beta-i+1})}dy\dots\,,
\end{equation}
so that:
\begin{equation}
\mathcal{G}_\beta^{(k)}(a,b) = \sum_{i=0}^{{\rm min}(k,\beta)}
  \theta(b-x_{\beta-i})\theta(x_{\beta-i+1}-a)\prod^{k}_{m=0\atop m\ne
    i}\frac{1}{x_{\beta}-x_{\beta-i+m}}\int_{{\rm max}(a,x_{\beta-i})}^{{\rm min}(b,x_{\beta-i+1})}dy\prod^{k}_{m=0\atop m\ne
    i}(y-x_{\beta-i+m})\,.
\end{equation}
It is easy to see that:
\begin{equation}\label{eq:expansion}
\prod^{k}_{m=0\atop m\ne
i}(y-x_{\beta-i+m})=\sum_{n=0}^k (-1)^n p_{\beta}^{(k)}(n)y^{k-n}\,,
\end{equation}
such that:
\begin{equation}\label{eq:linIntegral}
\begin{array}{rcl}
\displaystyle \mathcal{G}_\beta^{(k)}(a,b) &=&\displaystyle  \sum_{i=0}^{{\rm min}(k,\beta)}
  \theta(b-x_{\beta-i})\theta(x_{\beta-i+1}-a)\\
\\
&\times&\displaystyle \left[\prod^{k}_{m=0\atop m\ne
    i}\frac{1}{x_{\beta}-x_{\beta-i+m}}\right]\sum_{n=0}^k
         \frac{(-1)^n p_{\beta}^{(k)}(n)}{k-n+1}
         \left(\overline{b}^{k-n+1}-\overline{a}^{k-n+1}\right)\,.
\end{array}
\end{equation}
with $\overline{a} = {\rm max}(a,x_{\beta-i})$ and
$\overline{b} = {\rm min}(b,x_{\beta-i+1})$.
% For the moment we leave the integral unsolved, we will come back on
% that later because the situation is more complicated than that.
What is left to do is to determine the coefficients
$p_{\beta}^{(k)}$. For convenience, let us define the set
$\{r_1,\dots,r_k\}=\{x_{\beta-i},\dots,x_{\beta-1},x_{\beta+1},\dots,x_{\beta-i+k}\}$.\footnote{From
  the definition of the set $\{r_1,\dots,r_k\}$, it becomes clear that
  the subscript $\beta$ of the coefficients $p_{\beta}^{(k)}$ refers
  to the fact that this coefficients are computed on a vector of $k$
  nodes where the node $x_{\beta}$ has been removed.} The coefficients
$p_{\beta}^{(k)}$ defined in Eq.~(\ref{eq:expansion}) can be expressed
as:
\begin{equation}\label{eq:pncoef}
  p_{\beta}^{(k)}(n)=\sum_{i_1=1}^k r_{i_1}\sum_{i_2=i_1+1}^k r_{i_2}\dots\sum_{i_n=i_{n-1}+1}^k r_{i_n}\,.
\end{equation}
In order to obtain a convenient algorithm to compute the coefficients
$p_{\beta}^{(k)}$, we define the vectorial function:
\begin{equation}
\mathbf{f}^{(k)}(\mathbf{r},\mathbf{a})\quad\mbox{with components}\quad  f_j^{(k)}\left(\mathbf{r},\mathbf{a}\right)=\sum_{i=j+1}^k r_{i}a_{i}\,.
\end{equation}
It is important to notice that while $\mathbf{r}$ is a $k$-dimensional
vector with index running between 1 and $k$, $\mathbf{a}$ and
$\mathbf{f}^{(k)}$ are in principle infinite-dimensional vectors with
index running between $-\infty$ and $+\infty$.  However, given the
definition of its components in Eq.~(\ref{eq:pncoef}), it turns out
that $f_j^{(k)}=0$ for $j\geq k$. The same applies to $\mathbf{a}$
because, as we will see below, it has to be identified with some
$\mathbf{f}^{(k)}$.  The function $\mathbf{f}^{(k)}$ can now be used
to defined the vector $\mathbf{P}^{(k)}(n)$ recursively. The relevant
recursive relation is:
\begin{equation}
\mathbf{P}^{(k)}(n+1) = \mathbf{f}^{(k)}(\mathbf{r},\mathbf{P}^{(k)}(n))\quad\mbox{with}\quad\mathbf{P}^{(k)}(0) = \mathbf{1}\,.
\end{equation}
Finally, the coefficient $p_{\beta}^{(k)}(n)$ is the zero-th
component of the vector $\mathbf{P}^{(k)}(n)$, \textit{i.e.}
$p_{\beta}^{(k)}(n)\equiv P_0^{(k)}(n)$.

% As mentioned above, there is a complication. The discussion above
% applies to Lagrange interpolating functions written in terms of powers
% of $x$. Nonetheless, APFEL implements an interpolation procedure based
% on powers of $\ln x$. Specifically, the Lagrange polynomials look like
% this:
% \begin{equation}\label{eq:LagPolyLog}
%   \ell_i^{(k)}(x) = \prod^{k}_{m=0\atop m\ne
%     i}\frac{\ln x-\ln x_{\alpha+m}}{\ln x_{\alpha+i}-\ln x_{\alpha+m}}\,.
% \end{equation}
% Therefore, deriving and integrating w.r.t. $x$ needs to account for
% the presence of the logarithm. This is not particularly complicated
% for the derivative because the derivation above applies verbatim to
% $dg/d\ln x$ and this easily translates into $dg/dx$ using the chain
% rule:
% \begin{equation}
% \frac{dg}{dx} = \frac{d\ln x}{dx}\frac{dg}{d\ln x} = \frac{1}{x} \frac{dg}{d\ln x}\,.
% \end{equation}

% The integration is instead more complicated because the integral in
% Eq.~(\ref{eq:linIntegral}) needs to be replaced as follows:
% \begin{equation}
% \int_{\overline{a}}^{\overline{b}}dy\,y^{k-n}\quad\rightarrow\quad \int_{\overline{a}}^{\overline{b}} dy\,\ln^{k-n}y=\sum_{p=0}^{k-n}\frac{(-1)^{k-n+p}(k-n)!}{p!}\left[\overline{b}\ln^p \overline{b}-\overline{a}\ln^p \overline{a}\right]\,.
% \end{equation}
% with $\overline{a} = {\rm max}(a,x_{\beta-i})$ and
% $\overline{b} = {\rm min}(b,x_{\beta-i+1})$.
% Therefore, after some manipulation, Eq.~(\ref{eq:linIntegral}) becomes:
% \begin{equation}\label{eq:logIntegral}
% \begin{array}{rcl}
% \displaystyle \mathcal{G}_\beta^{(k)}(a,b) &=&\displaystyle
%                                                \sum_{j=0}^{{\rm min}(\beta,k)}
%   \theta(b-x_{\beta-j})\theta(x_{\beta-j+1}-a)\\
% \\
% &\times&\displaystyle\left[\prod^{k}_{\delta=0\atop \delta\ne
%     j}\frac{1}{\ln x_{\beta}-\ln x_{\beta-j+\delta}}\right]\left[\sum_{p=0}^k q_\beta^{(k)}(p)\frac{(-1)^{k+p} \left[\overline{b}\ln^{p} \overline{b}-\overline{a}\ln^p \overline{a}\right]}{p!}\right]\,.
% \end{array}
% \end{equation}
% with:
% \begin{equation}
%   q_\beta^{(k)}(p) = \sum_{\eta=p}^{k}
%   \eta!\,p_{\beta}^{(k)}(k-\eta)\,.
% \end{equation}

Now, we turn to derive derivation and integration formulas for the
generalised interpolation formula in Eq.~(\ref{generalCase4}). The
derivative is as simple as in the $t=0$ case, that is:
\begin{equation}\label{generalCase4}
\frac{dg}{dx} =
\sum_{\beta=\alpha(x)-t(x)}^{\alpha(x)-t(x)+k}\mathcal{D}_{\beta,t}^{(k)}(x) g(x_{\beta})\,,
\end{equation}
with:
\begin{equation}
\mathcal{D}_{\beta,t}^{(k)}(x) = \sum_{i=0}^{{\rm min}(k,\beta)}
\theta(x-x_{\beta-i+t(x)})\theta(x_{\beta-i+t(x)+1}-x) \left(\sum^{k}_{n=0\atop m\ne
i}\frac{1}{x_{\beta}-x_{\beta-i+n}}\prod^{k}_{m=0\atop m\ne
i,n}\frac{x-x_{\beta-i+m}}{x_{\beta}-x_{\beta-i+m}}\right)\,.
\end{equation}

Due to the presence of the function $t(x)$, defined in
Eq.~(\ref{eq:tdef}), the integration procedure is more involved. We
want to compute:
\begin{equation}
\begin{array}{rcl}
  I(a,b)&=&\displaystyle
  \int_a^b dy
  \sum_{\beta=\alpha(y)-t(y)}^{\alpha(y)-t(y)+k}\mathcal{I}_{\beta,t}^{(k)}(y)
  g(x_{\beta}) \\
\\
&=&\displaystyle \left[\int_a^{x_{\alpha(a)+1}}+ \sum_{\gamma=\alpha(a)+1}^{\alpha(b)}\int_{x_\gamma}^{x_{\gamma+1}}-\int_b^{x_{\alpha(b)+1}}\right]dy \sum_{\beta=\alpha(y) -t(y)}^{\alpha(y)-t(y)+k}\mathcal{I}_{\beta,t}^{(k)}(y)
  g(x_{\beta})\,.
\end{array}
\end{equation}
As in the case of $t=0$, each of the integrals above has a constant
value of $\alpha(y)$ and $t(y)$ so that sum over $\beta$ and integral
sign can be exchanged:
\begin{equation}\label{eq:integralT}
\begin{array}{rcl}
I(a,b) &=&\displaystyle  
\sum_{\beta=\alpha(a)
           -t(a)}^{\alpha(a)-t(a)+k}g(x_{\beta})\int_a^{x_{\alpha(a)+1}}dy\,\mathcal{I}_{\beta,t}^{(k)}(y)\\
\\
&+&\displaystyle
    \sum_{\gamma=\alpha(a)+1}^{\alpha(b)}\sum_{\beta=\gamma-t_\gamma}^{\gamma-t_\gamma+k}g(x_{\beta})\int_{x_\gamma}^{x_{\gamma+1}}dy\,\mathcal{I}_{\beta,t}^{(k)}(y)\\
\\
&-&\displaystyle \sum_{\beta=\alpha(b)-t(b)}^{\alpha(b)
    -t(b)+k}g(x_{\beta})\int_b^{x_{\alpha(b)+1}}dy\,\mathcal{I}_{\beta,t}^{(k)}(y)\,,
\end{array}
\end{equation}
with:
\begin{equation}
t_\gamma = t(x_\gamma) = \mbox{max}\left[\mbox{min}\left[\gamma,\alpha_t -2\right] -\alpha_t+k + 1, 0\right] \,.
\end{equation}
It turns out to be very complicated to write the expression in
Eq.~(\ref{eq:integralT}) in a more compact form, such as that in
Eq.~(\ref{eq:integralT0}). Therefore, we implement
Eq.~(\ref{eq:integralT}) as it is. The one thing left to do is to
solve the integrals. This is done by using the general formula:
\begin{equation}
\begin{array}{rcl}
  \displaystyle\int_{\ell_1}^{\ell_2}dy\,\mathcal{I}_{\beta,t}^{(k)}(y)
  &=&\displaystyle \sum_{i=0}^{{\rm min}(k,\beta)}
                                                                      \theta(\ell_2-x_{\beta-i+t_\ell})\theta(x_{\beta-i+t_\ell+1}-\ell_1)\\
  \\
                                                                  &\times&\displaystyle \left[\prod^{k}_{m=0\atop m\ne
                                                                           i}\frac{1}{x_{\beta}-x_{\beta-i+m}}\right]
                                                                           \sum_{n=0}^k \frac{(-1)^n p_{\beta}^{(k)}(n)}{k-n+1} \left(\overline{\ell}_2^{k-n+1}-\overline{\ell}_1^{k-n+1}\right)\,,
\end{array}
\end{equation}
with $t(\ell_1)=t(\ell_2)=t_\ell$, and
$\overline{\ell}_1={\rm max}(\ell_1,x_{\beta-i+t_\ell})$ and
$\overline{\ell}_2={\rm min}(\ell_2,x_{\beta-i+t_\ell+1})$.

\section{Cuts on the final-state leptons}

In this section we derive explicitly the phase-space reduction factor
$\mathcal{P}$ introduced in Sect.~\ref{sec:kincuts}. This factor is
defined as:
\begin{equation}\label{eq:PSredDef}
\mathcal{P}(Q,y,q_T) = \mathcal{P}(q) = \frac{\displaystyle \int_{\mbox{\footnotesize fid.
    reg.}}d^4p_1 d^4p_2 \,\delta(p_1^2) \delta(p_2^2)\theta(p_{1,0}) \theta(p_{2,0})\delta^{(4)}(p_1+p_2-q) g_{\mu\nu}L^{\mu\nu}(p_1,p_2)}{\displaystyle \int d^4p_1 d^4p_2\, \delta(p_1^2) \delta(p_2^2) \theta(p_{1,0}) \theta(p_{2,0})\delta^{(4)}(p_1+p_2-q) g_{\mu\nu}L^{\mu\nu}(p_1,p_2)}\,,
\end{equation}
where $p_1$ and $p_2$ are the four-momenta of the outgoing leptons
and $L^{\mu\nu}$ is the leptonic tensor that, assuming massless
leptons, reads:
\begin{equation}\label{eq:lepttens}
L^{\mu\nu}(p_1,p_2) = 4(p_1^{\mu}p_2^{\nu}+p_2^{\mu}p_1^{\nu}-g^{\mu\nu}p_1p_2)\,,
\end{equation}
so that:
\begin{equation}
g_{\mu\nu}L^{\mu\nu}(p_1,p_2) = -8(p_1p_2) = -4(p_1+p_2)^2\,.
\end{equation}
In the last step we have used the on-shell-ness of the leptons
($p_1^2=p_2^2=0$). The integral in the denominator of
Eq.~(\ref{eq:PSredDef}) is restricted to some \textit{fiducial
  region}. Finally, we find:
\begin{equation}\label{eq:PSredDef2}
\mathcal{P}(q) = \frac{\displaystyle \int_{\mbox{\footnotesize fid.
    reg.}}d^4p_1 d^4p_2 \,\delta(p_1^2) \delta(p_2^2) \theta(p_{1,0}) \theta(p_{2,0})\delta^{(4)}(p_1+p_2-q) (p_1+p_2)^2}{\displaystyle \int d^4p_1 d^4p_2\, \delta(p_1^2) \delta(p_2^2) \theta(p_{1,0}) \theta(p_{2,0})\delta^{(4)}(p_1+p_2-q) (p_1+p_2)^2}\,.
\end{equation}
The effect of integrating over the fiducial region can be implemented
by defining a generalised $\theta$-function, $\Phi(p_1,p_2)$, that is
equal to one inside the fiducial region and zero outside. This allows
one to integrate also the numerator of Eq.~(\ref{eq:PSredDef2}) over
the full phase-space of the two outgoing leptons:
\begin{equation}\label{eq:PSredDef3}
\mathcal{P}(q) = \frac{\displaystyle \int d^4p_1 d^4p_2 \,\delta(p_1^2) \delta(p_2^2) \theta(p_{1,0}) \theta(p_{2,0})\delta^{(4)}(p_1+p_2-q) \Phi(p_1,p_2) (p_1+p_2)^2}{\displaystyle \int d^4p_1 d^4p_2\, \delta(p_1^2) \delta(p_2^2) \theta(p_{1,0}) \theta(p_{2,0})\delta^{(4)}(p_1+p_2-q) (p_1+p_2)^2}\,.
\end{equation}
Now we can integrate over one of the outgoing momenta, say $p_2$,
exploiting the momentum-conservation $\delta$-function both in the
numerator and in the denominator. Specifically, the numerator of
Eq.~(\ref{eq:PSredDef3}) gives:
\begin{equation}
\begin{array}{c}
\displaystyle \int d^4p_1 d^4p_2\, \delta(p_1^2)
\delta(p_2^2) \theta(p_{1,0}) \theta(p_{2,0})\delta^{(4)}(p_1+p_2-q)
  \Phi(p_1,p_2) (p_1+p_2)^2 = \\
\\
\displaystyle Q^2 \int d^4p_1 \delta(p_1^2)
\delta((q-p_1)^2) \theta(p_{1,0})
  \theta(q_0-p_{1,0})\Phi(p_1,q-p_1)\,,
\end{array}
\end{equation}
and likewise in the denominator setting $\Phi(p_1,p_2)=1$. Finally,
renaming $p_1=p$, the phase-space reduction factor reads:
\begin{equation}\label{eq:PSredDef4}
  \mathcal{P}(q) = \frac{\displaystyle \int d^4p \delta(p^2) \delta((q-p)^2) \theta(p_{0})
    \theta(q_0-p_{0})  \Phi(p,q-p)}{\displaystyle \int d^4p \delta(p^2) \delta((q-p)^2) \theta(p_{0})
    \theta(q_0-p_{0})  }\,.
\end{equation}
The $\delta$-functions can now be used to constrain two of the four
components of the momentum $p$. The first, $\delta(p_2^2)$, is usually
used to set the first component of $p$, the energy, to the on-shell
value. Since the leptons are assumed to be massless, this
produces:
\begin{equation}\label{eq:phasespacemeasure}
\int d^4p\delta(p^2)\theta(p_0) = \int d^4p\delta(E^2-|\mathbf{p}|^2)\theta(E)=\int\frac{dEd^3\mathbf{p}}{2|\mathbf{p}|}\delta(E-|\mathbf{p}|)=\int\frac{d^3\mathbf{p}}{2|\mathbf{p}|}\,.
\end{equation}
Of course, the four-momentum $p$ appearing in the rest of the
integrand has to be set on shell ($E=|\mathbf{p}|$). Now we express
the three-dimensional measure $d^3\mathbf{p}$ in spherical coordinates
as:
\begin{equation}
d^3\mathbf{p} = |\mathbf{p}|^2d|\mathbf{p}|d(\cos\theta) d\phi\,.
\end{equation}
Then we make a change of variable from $(|\mathbf{p}|,\cos\theta)$ to
$(|\mathbf{p}_T|,\eta)$: the second set of variables are exactly those
on which kinematic cuts are imposed. We do so by knowing that:
\begin{equation}
\left\{
\begin{array}{l}
|\mathbf{p}| = |\mathbf{p}_T|\cosh\eta\,,\\
\cos\theta =\tanh\eta\,.
\end{array}
\right.
\end{equation}
This leads to:
\begin{equation}
\int\frac{d^3\mathbf{p}}{2 |\mathbf{p}|} = \frac12\int|\mathbf{p}|d|\mathbf{p}|d(\cos\theta) d\phi=\frac12\int|\mathbf{p}_T|d|\mathbf{p}_T|d\eta d\phi=\frac12\int d^2\mathbf{p}_T d\eta\,.
\end{equation}

Now we consider the second $\delta$-function:
\begin{equation}\label{eq:integralyeah!}
\frac12\int d^2\mathbf{p}_T d\eta\,\delta((q-p)^2)\theta(q_0-p_0)=\frac12\int_{-\infty}^\infty d\eta
\int_0^{2\pi} d\phi \int_0^\infty|\mathbf{p}_T|d|\mathbf{p}_T|\,\delta(Q^2-2p\cdot q) \theta(q_0-p_0)\,,
\end{equation}
being $q^2=Q^2$ and $p^2=0$. It is convenient to express the
four-vector $q$ in terms of $Q$, $y$, and $\mathbf{q}_T$:
\begin{equation}\label{eq:qexplicit}
q=\left(M\cosh y,\mathbf{q}_T,M\sinh y\right)\,.
\end{equation}
with $M=\sqrt{Q^2+|\mathbf{q}_T|^2}$. While:
\begin{equation}\label{eq:pexplicit}
p=\left(|\mathbf{p}_T|\cosh\eta,\mathbf{p}_T,|\mathbf{p}_T|\sinh\eta\right)\,,
\end{equation}
so that:
\begin{equation}
p\cdot q=|\mathbf{p}_T|M\left(\cosh\eta \cosh y-\sinh\eta\sinh
  y\right)-\mathbf{p}_T\cdot
\mathbf{q}_T=|\mathbf{p}_T|M\cosh\left(\eta - y\right)-\mathbf{p}_T\cdot \mathbf{q}_T\,.
\end{equation}
We can now assume that the two-dimensional vector $\mathbf{q}_T$ is
aligned with the $x$ axis so that
$\mathbf{p}_T\cdot \mathbf{q}_T =
|\mathbf{p}_T||\mathbf{q}_T|\cos\phi$(\footnote{In
  the general case in which $\mathbf{q}_T$ forms an angle $\beta$ with
  the $x$ axis, the scalar product would result in
  $|\mathbf{p}_T||\mathbf{q}_T|\cos(\phi-\beta)$. However, the angle
  $\beta$ could always be reabsorbed in a redefinition of the
  integration angle $\phi$ in
  Eq.~(\ref{eq:integralyeah!}).}). Therefore, the argument of the
$\delta$-function in Eq.~(\ref{eq:integralyeah!}) becomes:
\begin{equation}\label{eq:deltaargument}
f(|\mathbf{p}_T|,\eta,\phi) = Q^2-2 |\mathbf{p}_T|\left[M\cosh\left(\eta - y\right)-|\mathbf{q}_T|\cos\phi\right]\,.
\end{equation}
and that of the $\vartheta$-function
$M\cosh y-|\mathbf{p}_T|\cosh\eta$. It thus appears convenient to
integrate Eq.~(\ref{eq:integralyeah!}) over $|\mathbf{p}_T|$ first:
\begin{equation}\label{eq:firstintegral}
\frac12\int_0^\infty|\mathbf{p}_T|d|\mathbf{p}_T|\,\delta(Q^2-2p\cdot q) \theta(q_0-p_0)=\frac{\overline{p}_T^2}{2Q^2}\vartheta(M\cosh y-\overline{p}_T\cosh\eta)=\frac{\overline{p}_T^2}{2Q^2}\,,
\end{equation}
with(\footnote{Notice that the $\vartheta$-function has no effect. I
  have verified it numerically but I cannot see it analytically.}):
\begin{equation}\label{eq:overpT}
\overline{p}_T(\cos\phi) = \frac{Q^2}{2 \left[M\cosh\left(\eta - y\right)-|\mathbf{q}_T|\cos\phi\right]}=\frac{Q^2}{2 |\mathbf{q}_T|}\frac1{\left[\frac{M\cosh\left(\eta - y\right)}{|\mathbf{q}_T|}-\cos\phi\right]}\,.
\end{equation}
Now we turn to consider the integral in $d\phi$. To this end, the
following relations are useful:
\begin{equation}\label{eq:intoverphi}
\int_0^{2\pi}d\phi\, f(\cos\phi) = \int_{-1}^1\frac{dx}{\sqrt{1-x^2}}\left[f(x)+f(-x)\right]\,.
\end{equation}
and:
\begin{equation}\label{eq:complicatedintegral}
\int \frac{dx}{(a\pm
  x)^2\sqrt{1-x^2}}=\frac{\sqrt{1-x^2}}{(a^2-1)(x\pm
  a)}\pm\frac{a}{(a^2-1)^{3/2}}\tan^{-1}\left(\frac{1\pm ax}{\sqrt{a^2-1}\sqrt{1-x^2}}\right)\,.
\end{equation}
The last integral is such that:
\begin{equation}\label{eq:defintoverphi}
\int_{-1}^{1} \frac{dx}{(a\pm x)^2\sqrt{1-x^2}}=\frac{\pi a}{(a^2-1)^{3/2}}\,.
\end{equation}
We now use Eqs.~(\ref{eq:intoverphi})-(\ref{eq:defintoverphi}) to
compute:
\begin{equation}
\begin{array}{rcl}
&&\displaystyle
  \frac{1}{2Q^2}\int_0^{2\pi}d\phi\,[\overline{p}_T(\cos\phi)]^2 =
                                                                    \displaystyle
                                                                    \frac{Q^2}{4
                                                                    |\mathbf{q}_T|^2}\int_0^{2\pi}\frac{d\phi}{\left[\frac{M\cosh\left(\eta
                                                                    -
                                                                    y\right)}{|\mathbf{q}_T|}-\cos\phi\right]^2}\\
\\
&=&\displaystyle \frac{Q^2}{8|\mathbf{q}_T|^2}\int_{-1}^{1}\frac{dx}{\sqrt{1-x^2}}\left[\frac{1}{\left(\frac{M\cosh\left(\eta- y\right)}{|\mathbf{q}_T|}-x\right)^2}+\frac{1}{\left(\frac{M\cosh\left(\eta- y\right)}{|\mathbf{q}_T|}+x\right)^2}\right]\\
\\
&=&\displaystyle \frac{Q^2}{8}\Bigg\{\frac{|\mathbf{q}_T|^2 x\sqrt{1-x^2}}{(M ^2\cosh ^2\left(\eta- y\right)-|\mathbf{q}_T|^2)(x^2 |\mathbf{q}_T|^2-
  M ^2\cosh ^2\left(\eta- y\right))}\\
\\
&-&\displaystyle \frac{M\cosh\left(\eta-
    y\right)}{(M^2\cosh^2\left(\eta-
    y\right)-|\mathbf{q}_T|^2)^{3/2}}\Bigg[\tan^{-1}\left(\frac{|\mathbf{q}_T|-
    xM\cosh\left(\eta-y\right)}{\sqrt{(M^2\cosh^2\left(\eta-y\right)-|\mathbf{q}_T|^2)}\sqrt{1-x^2}}\right)\\
\\
&-&\displaystyle\tan^{-1}\left(\frac{|\mathbf{q}_T|+
    xM\cosh\left(\eta-y\right)}{\sqrt{(M^2\cosh^2\left(\eta-y\right)-|\mathbf{q}_T|^2)}\sqrt{1-x^2}}\right)\Bigg]\Bigg\}_{-1}^{1}\\
\\
&=&\displaystyle \frac{\pi
  Q^2M\cosh\left(\eta -
    y\right)}{4(M^2\cosh^2\left(\eta -
    y\right)-|\mathbf{q}_T|^2)^{3/2}}
\end{array}
\end{equation}
We can go further and solve also the integral in $\eta$:
\begin{equation}\label{eq:remarkableintegral}
\begin{array}{l}
  \displaystyle \int d^4p \delta(p^2) \delta((q-p)^2) \theta(p_{0})
  \theta(q_0-p_{0})=\int_{-\infty}^\infty
  d\eta\frac{\pi Q^2M\cosh(\eta-y)}{4(M^2\cosh^2(\eta-y)-|\mathbf{q}_T|^2)^{3/2}}= \\
  \\
  \displaystyle\frac{\pi }{4}\frac{Q^2}{M^2}\int_{-\infty}^\infty
  \frac{d(\sinh\eta)}{\left(\sinh^2(\eta-y)+\frac{Q^2}{M^2}\right)^{3/2}}= \frac{\pi}{4} \frac{Q^2}{M^2}\left[\frac{M^2}{Q^2}\frac{\sinh\eta}{\sqrt{\sinh^2\eta+\frac{Q^2}{M^2}}}\right]_{-\infty}^{\infty}= \frac{\pi}{2}\,.
\end{array}
\end{equation}
Remarkably, this result gives us the denominator of
Eq.~(\ref{eq:PSredDef4}). We now need to compute the numerator by
inserting the appropriate function $\Phi$. In our case, the kinematic
cuts are identical for the outgoing leptons and read:
\begin{equation}
\eta_{\rm
  min} < \eta_{1(2)} < \eta_{\rm max}\quad\mbox{and}\quad |\mathbf{p}_{T,1(2)}| > p_{T,\rm min}\,.
\end{equation}
Therefore, the function $\Phi$ factorises into two identical functions
as:
\begin{equation}
\Phi(p_1,p_2) = \Theta(p_1)\Theta(p_2)\,,
\end{equation}
with:
\begin{equation}
  \Theta(p) = \vartheta(\eta - \eta_{\rm min})\vartheta(\eta_{\rm max}-\eta) \vartheta(|\mathbf{p}_{T}| - p_{T,\rm min}) \,. 
\end{equation}
Regerring to Eq.~(\ref{eq:PSredDef4}), and considering that:
\begin{equation}
q-p=\left(M\cosh y-|\mathbf{p}_T|\cosh\eta,\mathbf{q}_T-\mathbf{p}_T,M\sinh y-|\mathbf{p}_T|\sinh\eta\right)\,.
\end{equation}
we thus have:
\begin{equation}\label{eq:intdomain}
\begin{array}{ll}
&\Phi(p,q-p) = \Theta(p) \Theta(q-p)=\\
\\
&\displaystyle 
\vartheta(\eta - \eta_{\rm min}) \vartheta(\eta_{\rm max}-\eta)
  \times\\
\\
&\displaystyle \vartheta(|\mathbf{p}_{T}| - p_{T,\rm min})\times\\
\\
&\displaystyle \vartheta\left(\frac12\ln\left(\frac{M\cosh y-|\mathbf{p}_T|\cosh\eta+M\sinh y-|\mathbf{p}_T|\sinh\eta}{M\cosh y-|\mathbf{p}_T|\cosh\eta-M\sinh y+|\mathbf{p}_T|\sinh\eta}\right)-\eta_{\rm min}\right)\times\\
\\
&\displaystyle \vartheta\left(\eta_{\rm
  max}-\frac12\ln\left(\frac{M\cosh y-|\mathbf{p}_T|\cosh\eta+M\sinh
  y-|\mathbf{p}_T|\sinh\eta}{M\cosh y-|\mathbf{p}_T|\cosh\eta-M\sinh
  y+|\mathbf{p}_T|\sinh\eta}\right)\right)\times\\
\\
&\vartheta(|\mathbf{q}_{T}-\mathbf{p}_{T}| - p_{T,\rm min})=\\
\\
1):\quad&\displaystyle \vartheta(\eta-\eta_{\rm min}) \times\vartheta(\eta_{\rm max}-\eta) \times\\
\\
2):\quad&\displaystyle \vartheta(\overline{p}_T - p_{T,\rm min})\times\\
\\
3):\quad&\displaystyle 
  \vartheta\left(\frac12\ln\left(\frac{Me^y-\overline{p}_Te^\eta}{Me^{-y}-\overline{p}_Te^{-
\eta}}\right)-\eta_{\rm min}\right)\times\vartheta\left(\eta_{\rm max}-\frac12\ln\left(\frac{Me^y-\overline{p}_Te^\eta}{Me^{-y}-\overline{p}_Te^{-
\eta}}\right)\right)\times\\
\\
4):\quad&\displaystyle \vartheta(\sqrt{|\mathbf{q}_T|^2+\overline{p}_T^2-2 |\mathbf{q}_T|\overline{p}_T\cos\phi} - p_{T,\rm min})\,,
\end{array}
\end{equation}
where in the last step we have replaced $|\mathbf{p}_T|$ with
$\overline{p}_T$ defined Eq.~(\ref{eq:overpT}). Now the question is
identifying the integration domain defined by $\Phi(p,q-p)$ on the
$(\eta,\cos\phi)$-plane. Since the $\theta$-functions in
Eq.~(\ref{eq:PSredDef4}) will be used inside a double nested integral
over $x=\cos\phi$ first and $\eta$ second, it is convenient to rewrite
the function $\Phi(p,q-p)$ in Eq.~(\ref{eq:intdomain}) as follows:
\begin{equation}\label{eq:almostfinal}
\begin{array}{rcl}
\Phi(p,q-p) &=&\displaystyle \vartheta(\eta-\eta_{\rm min}) \times
\vartheta(\eta_{\rm max}-\eta) \\
\\
&\times& \vartheta(x - f^{(2)}(\eta,
                p_{T,\rm min})) \\
\\
&\times&\displaystyle
         \vartheta(f^{(3)}(\eta,\eta_{\rm min})-x) \times \vartheta(f^{(3)}(\eta,\eta_{\rm max})-x)\\
\\
&\times&\vartheta(f^{(4)}(\eta,
         p_{T,\rm min})-x)
         
         \,,
\end{array}
\end{equation}
with:
\begin{equation}\label{eq:relevantfuncs}
\begin{array}{rcl}
f^{(2)}(\eta, p_{T,\rm cut}) & = &\displaystyle \frac{2M p_{T,\rm min}\cosh(\eta-y) 
                    - Q^{2}}{2p_{T,\rm cut}
                    |\mathbf{q}_T|}\,, \\
\\
f^{(3)}(\eta,\eta_{\rm cut}) & = &\displaystyle \frac{M \cosh(\eta-y)}{|\mathbf{q}_T|
                    }-\frac{Q^{2} \left(\sinh(\eta
                                   -y)\coth(y-\eta_{\rm cut})+\cosh(\eta-y)\right)}{2|\mathbf{q}_T|  M}\,,\\
\\
f^{(4)}(\eta, p_{T,\rm cut}) & = &\displaystyle \frac{M \cosh(\eta-y)(Q^2 - 2
                    p_{T,\rm cut}^{2} + 2 |\mathbf{q}_T|^2)- Q^{2} \sqrt{M^{2} \sinh ^{2} (\eta-y) + p_{T,\rm min}^{2} }}{2 |\mathbf{q}_T| \left(M^{2} - p_{T,\rm min}^{2}\right)}\,.
\end{array}
\end{equation}
Considering that $1\leq\cos\phi\leq 1$, the integration domain is
limited to this region. Therefore, Eq.~(\ref{eq:almostfinal}) can be
written in an even more convenient way as:
\begin{equation}\label{eq:final}
\begin{array}{rcl}
\Phi(p,q-p) &=& \vartheta(\eta-\eta_{\rm min})\vartheta(\eta_{\rm
  max}-\eta)  \\
\\
&\times&\vartheta(x -
  \mbox{max}[f^{(2)}(\eta,p_{T,\rm min}),-1])\\
\\
&\times&\vartheta(\mbox{min}[f^{(3)}(\eta,\eta_{\rm min}),f^{(3)}(\eta,\eta_{\rm
         max}), f^{(4)}(\eta,p_{T,\rm
         min}),1]-x)
\end{array}
\end{equation}
such that a double integral over $\eta$ and $x$ would read:
\begin{equation}
\int_{-\infty}^{\infty}d\eta\int_{-1}^{1}dx\,\Phi(p,q-p)\dots =
\int_{\eta_{\rm min}}^{\eta_{\rm
    max}}d\eta\,\vartheta(x_2(\eta)-x_1(\eta))\int_{x_1(\eta)}^{x_2(\eta)}dx\dots\,.
\end{equation}
with:
\begin{equation}
x_1(\eta) = \mbox{max}[f^{(2)}(\eta,p_{T,\rm min}),-1]
\end{equation}
and:
\begin{equation}
x_2(\eta) = \mbox{min}[f^{(3)}(\eta,\eta_{\rm min}),f^{(3)}(\eta,\eta_{\rm
         max}),f^{(4)}(\eta,p_{T,\rm
         min}),1]\,.
\end{equation}

\begin{figure}[t]
  \begin{centering}
    \includegraphics[width=0.8\textwidth]{plots/IntDomain}
    \caption{The red area indicates the integration domain of the
      numerator in of the phase-space reduction factor
      Eq.~(\ref{eq:PSredDef4}) for $p_{T,\rm min}=20$ GeV and
      $-\eta_{\rm min}=\eta_{\rm max}=2.4$ at $Q=91$ GeV, $|\mathbf{q}_T|=10$ GeV and
      $y=1$.\label{fig:IntDomain}}
  \end{centering}
\end{figure}
As an example, Fig.~\ref{fig:IntDomain} shows the integration domain
of the numerator in of the phase-space reduction factor
Eq.~(\ref{eq:PSredDef4}) for $p_{T,\rm min}=20$ GeV and
$-\eta_{\rm min}=\eta_{\rm max}=2.4$ at $Q=91$ GeV,
$|\mathbf{q}_T|=10$ GeV and $y=1$.  The gray band corresponds to the
region $1\leq\cos\phi\leq 1$. The $\theta$-function 1) in
Eq.~(\ref{eq:intdomain}) limits the region to the vertical stip
defined by $\eta_{\rm min} < \eta < \eta_{\rm max}$ (black vertical
lines), the $\theta$-function 2) gives the red lines, the
$\theta$-functions 3) the blue lines , and the $\theta$-function 4)
the green lines.

Gathering all pieces, the final expression for the phase-space
reduction factor reads:
\begin{equation}\label{eq:finalformula}
  \mathcal{P}(Q,y,q_T)=\displaystyle \int_{\eta_{\rm
      min}}^{\eta_{\rm
      max}}d\eta\,\vartheta(x_2(\eta)-x_1(\eta))\left[F(x_2(\eta),\eta)-F(x_1(\eta) ,\eta)\right]
\end{equation}
with:
\begin{equation}\label{eq:integrandF}
\begin{array}{rcl}
\displaystyle F(x ,\eta)&=&\displaystyle \frac{1}{4\pi}\frac{Q^2}{E_q^2-q_T^2}\Bigg\{\frac{q_T^2 x\sqrt{1-x^2}}{x^2 q_T^2-
  E_q^2}\\
\\
&-&\displaystyle \frac{E_q}{\sqrt{E_q^2-q_T^2}}\left[\tan^{-1}\left(\frac{q_T-
    xE_q}{\sqrt{E_q^2-q_T^2}\sqrt{1-x^2}}\right)-\displaystyle\tan^{-1}\left(\frac{q_T+
    xE_q}{\sqrt{E_q^2-q_T^2}\sqrt{1-x^2}}\right)\right]\Bigg\}\
\end{array}
\end{equation}
where we have defined $E_q = M\cosh(\eta-y)$ and
$q_T=|\mathbf{q}_T|$.

Let us consider the case $y=q_T=0$. For simplicity, we also take
$\eta_{\rm min} = -\eta_{\rm max}$. In these conditions,
Eq.~(\ref{eq:integrandF}) reduces to:
\begin{equation}\label{eq:F00}
F(x,\eta)=\displaystyle \frac{1}{4\pi}\frac{1}{\cosh^2(\eta)}\left[\tan^{-1}\left(\frac{
    x}{\sqrt{1-x^2}}\right)-\displaystyle\tan^{-1}\left(-\frac{
    x}{\sqrt{1-x^2}}\right)\right]\,.
\end{equation}
As evident from Eq.~(\ref{eq:relevantfuncs}), for $q_T=0$ all
functions $f^{(2)}$, $f^{(3)}$, and $f^{(4)}$ diverge. The relevant
question, though, is whether they go to plus or minus infinity
depending on the value of $Q$. Of course, $q_T$ will tend to zero
positively so we find:
\begin{equation}
\begin{array}{l}
\displaystyle f^{(2)}(\eta,p_{T,\rm min})\rightarrow \infty\times\mbox{sign}\left[2 p_{T,\rm min}\cosh(\eta)-Q\right]\,,\\
\\
\displaystyle f^{(3)}(\eta,\eta_{\rm min}= -\eta_{\rm max}) \rightarrow +\infty\\
\\
\displaystyle f^{(3)}(\eta,\eta_{\rm max}) \rightarrow -\infty\,,\\
\\
\displaystyle f^{(4)}(\eta,p_{T,\rm min}) \rightarrow \infty\times\mbox{sign}\left[\frac{\cosh(\eta)(Q^2 - 2
                    p_{T,\rm min}^{2})- Q\sqrt{Q^{2} \sinh^{2}(\eta) + p_{T,\rm min}^{2} }}{Q^{2} - p_{T,\rm min}^{2}}\right]\,, 
\end{array}
\end{equation}
Therefore, $f^{(3)}$ never actually contributes. In addition, for the
$\theta$-function in Eq.~(\ref{eq:finalformula}) to be different from
zero, we need $f^{(2)}(\eta)\rightarrow -\infty$ and
$f^{(3)}(\eta)\rightarrow \infty$. These both translate into
$Q\geq 2 p_{T,\rm min}\cosh(\eta)$. This inequality is satisfied only
if $Q\geq 2p_{T,\rm min}$ for:
\begin{equation}\label{eq:etabardef}
-\overline{\eta}\leq\eta\leq \overline{\eta}\quad\mbox{with}\quad \overline{\eta} =\cosh^{-1}\left(\frac{Q}{2p_{T,\rm min}}\right)\,.
\end{equation}
Therefore, the phase-space reduction factor eventually becomes:
\begin{equation}
\begin{array}{rcl}
  \mathcal{P}(Q,0,0)&=&\displaystyle\frac12\vartheta(Q- 2p_{T,\rm min})\displaystyle \int_{-\eta_{\rm
      max}}^{\eta_{\rm
      max}}\frac{d\eta}{\cosh^2\eta}\,\vartheta(\eta+\overline{\eta})
  \vartheta(\overline{\eta}-\eta)\\
\\
&=&\displaystyle\vartheta(Q- 2p_{T,\rm
    min})\tanh(\mbox{max}[\eta_{\rm max},\overline{\eta}])\,.
\end{array}
\end{equation}
This result can be written more explicitly as:
\begin{equation}\label{eq:partcase}
\mathcal{P}(Q,0,0) = 
\left\{
\begin{array}{ll}
0 & \quad Q< 2p_{T,\rm min}\,,\\
\displaystyle \tanh(\overline{\eta})=\left(1+\frac{2p_{T,\rm min}}{Q}\right)\sqrt{1-\frac{4 p_{T,\rm min}}{Q+2p_{T,\rm min}}}& \quad 2p_{T,\rm min} \leq Q < 2p_{T,\rm min}\cosh\eta_{\rm max}\,,\\
\tanh(\eta_{\rm max}) & \quad Q \geq 2p_{T,\rm min}\cosh\eta_{\rm max}\,.
\end{array}
\right.
\end{equation}
This differs from Eq.~(24) of Ref.~\cite{Scimemi:2017etj}. Despite the
three different regions coincide, the behavior of the phase-space
reduction factor for all regions but for $Q< 2p_{T,\rm min}$ is
different. In favour of our result there is the fact that
$\mathcal{P}(Q,0,0)$ in Eq.~(\ref{eq:partcase}) is continuous at
$Q = 2p_{T,\rm min}\cosh\eta_{\rm max}$ while that of
Ref.~\cite{Scimemi:2017etj} is not. In addition, when setting
$p_{T,\rm min} = 0$ and $\eta_{\rm max}=\infty$, \textit{i.e.} no
cuts, our result tends to $\mathcal{P}(Q,0,0)=\tanh(\infty)=1$, as it
should. While the result in Eq.~(24) of Ref.~\cite{Scimemi:2017etj}
actually diverges in this limit.

The integrand of Eq.~(\ref{eq:finalformula}), due to the behaviour of
$x_1$ and $x_2$ as functions of $\eta$, a piecewise
function. Therefore, its numerical integration is problematic in that
quadrature algorithms assume the integrand be continuos over the
integration range. The solution is to identify the discontinuity
points and integrate the function separately over the resulting
ranges. However, the complexity of the integration region
(\textit{e.g.} see Fig.~\ref{fig:IntDomain}) makes the analytical
identification of the discontinuity points very hard to achieve.

\subsection{Contracting the leptonic tensor with $g_\perp^{\mu\nu}$}

The calculation done in the previous section holds when contracting
the leptonic tensor $L_{\mu\nu}$ with the metric tensor $g^{\mu\nu}$
associated with the Lorentz structure of the hadronic tensor. However,
at small values of $|\mathbf{q}_T|$, the leading-power Lorentz
structure that one needs to multiply the leptonic tensor for is:
\begin{equation}
g_\perp^{\mu\nu} = g^{\mu\nu}+z^\mu z^\nu-t^\mu t^\nu
\end{equation}
where the vectors $z^\mu$ and $t^\mu$ in the Collins-Soper (CS) frame
are defined as:
\begin{equation}\label{eq:auxvects}
\begin{array}{l}
\displaystyle z^\mu = (\sinh y,\mathbf{0},\cosh y)\,,\\
\\
\displaystyle t^\mu = \frac{q^\mu}{Q}\,,
\end{array}
\end{equation}
and they are such that $z^2=-1$, $t^2=1$ and $zq = 0$. if we use the
on-shell-ness of $p_1$ and $p_2$ ($p_1^2=p_2^2=0$) and the momentum
conservation ($p\equiv p_1$, $p_2=q-p$), we find that
$t^\mu t^\nu L_{\mu\nu}=0$ and the quantity above reduces to:
\begin{equation}\label{eq:LT}
  L_\perp = g_\perp^{\mu\nu}L_{\mu\nu} = 4\left[\frac12q^2 + 2(zp)^2\right] = 2Q^2\left[1+4 \sinh^2(y-\eta)\frac{|\mathbf{p}_T|^2}{Q^2}\right]\,.
\end{equation}
Therefore, we need to introduce this factor in both the numerator and
the denominator of Eq.~(\ref{eq:PSredDef4}). Following the same steps
of the previous section, up to a factor $2Q^2$, this leads us to
replace the integral in Eq.~(\ref{eq:firstintegral}) with(\footnote{We
  removed the $\theta$-function as we know it does not have any
  effect.}):
\begin{equation}\label{eq:firstintegralNew}
  \frac12 \int_0^\infty|\mathbf{p}_T|\left[1+4\sinh^2(y-\eta)
  \frac{|\mathbf{p}_T|^2}{Q^2}\right]d|\mathbf{p}_T|\,\delta(Q^2-2p\cdot
  q) =\frac{2\overline{p}_T^2}{Q^2}+
  2\sinh^2(y-\eta)\frac{\overline{p}_T^4} {Q^4}\,.
\end{equation}
We can still use Eq.~(\ref{eq:complicatedintegral}) for the first term
in the r.h.s. of the equation above. For the second, instead we need
to use:
\begin{equation}\label{eq:complicatedintegral2}
\begin{array}{rcl}
\displaystyle\int \frac{dx}{(a\pm
  x)^4\sqrt{1-x^2}}&=&\displaystyle\frac{\sqrt{1-x^2}\left[(11a^2+4)x^2\pm
                       3 a(9a^2+1)x + (18a^4-5a^2+2)\right]}{6(a^2-1)^3(x\pm
  a)^3}\\
\\
&\pm&\displaystyle\frac{a(2a^2+3)}{2(a^2-1)^{7/2}}\tan^{-1}\left(\frac{1\pm
      ax}{\sqrt{a^2-1}\sqrt{1-x^2}}\right)\,,
\end{array}
\end{equation}
that is such that:
\begin{equation}
\int_{-1}^{1} \frac{dx}{(a\pm
  x)^4\sqrt{1-x^2}}=\frac{\pi a(2a^2+3)}{2(a^2-1)^{7/2}}\,.
\end{equation}
In our particular case, the integrand we are considering is the second
term in the r.h.s. term of Eq.~(\ref{eq:firstintegralNew}):
\begin{equation}\label{eq:integralmmm}
\begin{array}{l}
\displaystyle
  \frac{2\sinh^2(y-\eta)}{Q^4}\int_{-1}^{1}d(\cos\phi)\overline{p}_T^4(\cos\phi)=\\
\\
\displaystyle\frac{Q^4}{8q_T^4} \sinh^2(y-\eta) \int_{-1}^{1} \frac{dx}{\sqrt{1-x^2}}\left[\frac{1}{(a+
      x)^4}+\frac1{(a-
      x)^4}\right]= \frac{\pi Q^4}{8q_T^4}\sinh^2(y-\eta) \frac{
  a(2a^2+3)}{(a^2-1)^{7/2}}\,.
\end{array}
\end{equation}
with:
\begin{equation}
a =\frac{M}{q_T}\cosh(y-\eta)\,.
\end{equation}
Now we need to integrate Eq.~(\ref{eq:integralmmm}) over $\eta$:
\begin{equation}
  \frac{\pi Q^4}{8q_T^4} \int_{-\infty}^{\infty}d\eta\sinh^2(y-\eta)\frac{
    a(2a^2+3)}{(a^2-1)^{7/2}}\,.
\end{equation}
If we make the following change of variable in the integral above:
\begin{equation}
z=\frac{M}{q_T}\sinh(y-\eta)
\end{equation}
such that:
\begin{equation}
a^2 = z^2+\frac{M^2}{q_T^2}\quad\mbox{and}\quad dz = -ad\eta\,,
\end{equation}
the integral above becomes:
\begin{equation}
\frac{\pi Q^4}{4M^2 q_T^2} \int_{-\infty}^{\infty}dz\frac{
  z^2\left(z^2+\frac{M^2}{q_T^2}+\frac32\right)}{\left(z^2+\frac{M^2}{q_T^2}-1\right)^{7/2}}=\frac{\pi}{6}\,.
\end{equation}
Putting this result together with Eq.~(\ref{eq:remarkableintegral})
and taking into account the factor $2Q^2$ in Eq.~(\ref{eq:LT}), we find
that:
\begin{equation}\label{eq:normalisation}
\begin{array}{l}
  \displaystyle \int d^4p \delta(p^2) \delta((q-p)^2) \theta(p_{0})
  \theta(q_0-p_{0})L_\perp = \frac{4\pi}{3}Q^2\,.
\end{array}
\end{equation}
This result agrees with Eq.~(2.38) of Ref.~\cite{Scimemi:2017etj}, up
to a factor four. This provides the denominator of the
phase-space-reduction factor $\mathcal{P}$. The structure of
$\mathcal{P}$ will be exactly like that in
Eq.~(\ref{eq:finalformula}), the only thing we need to do is to
identify the correct function $F(x,\eta)$. To this end, we need to
make the following replacement for the function $F$ given in
Eq.~(\ref{eq:integrandF}) with:
\begin{equation}\label{eq:FGcombination}
F(x,\eta)\rightarrow \overline{F}(x,\eta) = \frac34 F(x,\eta)+ \frac14 G(x,\eta)\,,
\end{equation}
where:
\begin{equation}\label{eq:integrandG}
\begin{array}{rcl}
\displaystyle G(x ,\eta)&=&\displaystyle 
                            \frac{1}{16\pi }\sinh^2(y-\eta)\frac{Q^4}{(E_q^2-q_T^2)^3}
                            \Bigg\{\sqrt{1-x^2}q_T\\
\\
&\times&\displaystyle\Bigg[\frac{(11E_q^2q_T^2+4q_T^4)x^2+
                       3 E_qq_T(9E_q^2+q_T^2)x + (18E_q^4-5E_q^2q_T^2+2q_T^4)}{(xq_T+
  E_q)^3}\\
\\
&+&\displaystyle\frac{(11E_q^2q_T^2+4q_T^4)x^2-
                       3 E_qq_T(9E_q^2+q_T^2)x + (18E_q^4-5E_q^2q_T^2+2q_T^4)}{(xq_T-
  E_q)^3}\Bigg]\\
\\
&-&\displaystyle\frac{6E_q (2E_q^2+3q_T^2)}{\sqrt{E_q^2-q_T^2}}\left[\tan^{-1}\left(\frac{q_T-
      xE_q}{\sqrt{E_q^2-q_T^2}\sqrt{1-x^2}}\right)-\tan^{-1}\left(\frac{q_T+
      xE_q}{\sqrt{E_q^2-q_T^2}\sqrt{1-x^2}}\right)\right]
\Bigg\}\,.
\end{array}
\end{equation}
Finally, combining the functions $F$ and $G$ given in
Eqs.~(\ref{eq:integrandF}) and~(\ref{eq:integrandG}), respectively,
according to Eq.~(\ref{eq:FGcombination}) to obtain $\overline{F}$,
and replacing $F$ with $\overline{F}$ in Eq.~(\ref{eq:finalformula})
gives the phase-space-reduction factor $\mathcal{P}(Q,y,q_T)$ when the
leptonic tensor $L_{\mu\nu}$ is contracted with the transverse metrics
$g_\perp^{\mu\nu}$.

As a final check, it is interesting to compute $\mathcal{P}$ when
$y=q_T=0$, again assuming $\eta_{\rm min} = -\eta_{\rm max}$. In this
limit $F$ reduces to the expression in Eq.~(\ref{eq:F00}), while $G$
becomes:
\begin{equation}
\begin{array}{rcl}
\displaystyle G(x ,\eta)&=&\displaystyle 
                            \frac{3}{4\pi }\frac{\sinh^2(\eta)}{\cosh^4(\eta)}
                            \Bigg\{\left[\tan^{-1}\left(\frac{
      x}{\sqrt{1-x^2}}\right)-\tan^{-1}\left(-\frac{
      x}{\sqrt{1-x^2}}\right)\right]
\Bigg\}\,,
\end{array}
\end{equation}
such that:
\begin{equation}
\begin{array}{rcl}
  \mathcal{P}(Q,0,0)&=&\displaystyle\frac38\vartheta(Q- 2p_{T,\rm min})\displaystyle \int_{-\eta_{\rm
      max}}^{\eta_{\rm
      max}}d\eta\left[\frac{\cosh^2(\eta)+\sinh^2(\eta)}{\cosh^4(\eta)}\right]\,\vartheta(\eta+\overline{\eta})
  \vartheta(\overline{\eta}-\eta)\\
\\
&=&\displaystyle\vartheta(Q- 2p_{T,\rm
    min})\tanh(\mbox{max}[\eta_{\rm max},\overline{\eta}])\left[1-\frac{1}{4\cosh^2(\mbox{max}[\eta_{\rm max},\overline{\eta}])}\right]\,,
\end{array}
\end{equation}
with $\overline{\eta}$ defined in Eq.~(\ref{eq:etabardef}). The
relation above can be written more explicitly as:
\begin{equation}\label{eq:partcase2}
{\footnotesize
\mathcal{P}(Q,0,0) = 
\left\{
\begin{array}{ll}
0 & \quad Q< 2p_{T,\rm min}\,,\\
 \tanh(\overline{\eta})\left[1-\frac{1}{4\cosh^2(\overline{\eta})}\right]=\left(1-\frac{p_{T,\rm min}^2}{Q^2}\right)\sqrt{1-\frac{4 p_{T,\rm min}^2}{Q^2}}& \quad 2p_{T,\rm min} \leq Q < 2p_{T,\rm min}\cosh\eta_{\rm max}\,,\\
 \tanh(\eta_{\rm max})\left[1-\frac{1}{4\cosh^2(\eta_{\rm max})}\right] & \quad Q \geq 2p_{T,\rm min}\cosh\eta_{\rm max}\,.
\end{array}
\right.}
\end{equation}

The reason why we kept $\eta_{\rm min} \neq -\eta_{\rm max}$ is that
in some cases it may be required to implement an asymmetric cut,
$\eta_{\rm min}<\eta<\eta_{\rm max}$. This is the case, for example,
of the LHCb experiment that delivers data only in the forward region
($2 < \eta < 4.5$).
\begin{figure}[t]
  \begin{centering}
    \includegraphics[width=0.8\textwidth]{plots/IntDomainAsy}
    \caption{Same as Fig.~\ref{fig:IntDomain} for the asymmetric
      rapidity cut $2<\eta < 4.5$ at $y=3$.\label{fig:IntDomainAsy}}
  \end{centering}
\end{figure}
As an example, Fig.~\ref{fig:IntDomainAsy} shows the integration
domain of the phase-space reduction factor Eq.~(\ref{eq:PSredDef4})
for $p_{T,\rm min}=20$ GeV and $2<\eta < 4.5$ at $Q=91$ GeV,
$|\mathbf{q}_T|=10$ GeV and $y=3$.

\subsection{Parity-violating contribution}

In the presence of cuts on the final-state leptons and for invariant
masses around the $Z$ mass, parity-violating effects arise. As we will
show below, these effects integrate to zero when removing the leptonic
cuts. This contribution stems from interference of the antisymmetric
contributions to the lepton tensor, proportional to $p_1^{\mu}
p_2^{\nu}\epsilon_{\mu\nu\rho\sigma}$, and the hadronic tensor,
proportional to $\epsilon_{\perp}^{\mu\nu}$ defined as:
\begin{equation}
\epsilon_{\perp}^{\mu\nu}\equiv \epsilon^{\mu\nu\rho\sigma}t_\rho z_\sigma\,,
\end{equation}
where $t^\mu$ and $z^\mu$ are given in Eq.~(\ref{eq:auxvects}).
Therefore, the contribution we are after results from the contraction
of the following Lorentz structures:
\begin{equation}
L_{\rm PV}\equiv p_1^{\mu}
p_2^{\nu}\epsilon_{\mu\nu\rho\sigma}\epsilon_{\perp}^{\rho\sigma}\,.
\end{equation}
After some manipulation, one finds:
\begin{equation}\label{eq:pvphasespace}
\begin{array}{rcl}
\displaystyle L_{\rm PV}&=& \displaystyle
p_1^{\mu}
p_2^{\nu}\epsilon_{\mu\nu\rho\sigma}\epsilon^{\rho\sigma\alpha\beta}t_\alpha
z_\beta= -2 p_1^{\mu}
p_2^{\nu}\delta_\mu^\alpha \delta_\nu^\beta t_\alpha \\
\\
&=&\displaystyle -2 (p_1 t)(p_2 z) = -2 (pt)\left[(qz)-(pz)\right] = 2(pt)(pz)\\
\\
&=&\displaystyle \frac{2|\mathbf{p}_T|^2}{Q}\sinh(y-\eta)\left[M\cosh(y-\eta)-|\mathbf{q}_T|\cos\phi\right]\,,
\end{array}
\end{equation}
where I have defined $p_1\equiv p$ and used the equalities
$p_2 = q - p$, and $zq=0$. To compute the third line I have used the
explicit parameterisation of $q$ and $p$ given in
Eqs.~(\ref{eq:qexplicit}) and~(\ref{eq:pexplicit}), respectively. The
presence of $\sinh(y-\eta)$ in Eq.~(\ref{eq:pvphasespace}) is such
that integrating over the full range in the lepton rapidity $\eta$
nullifies this contribution:
\begin{equation}\label{eq:noPVcontr}
\int_{-\infty}^{\infty} d\eta\,L_{\rm PV} = 0\,.
\end{equation}
Therefore, it turns out that, for observables inclusive in the lepton
phase space, the parity violating term does not give any
contribution. Conversely, the presence of cuts on the final-state
leptons may prevent Eq.~(\ref{eq:noPVcontr}) from being satisfied
leaving a residual contribution. In order to quantify this effect, we
take the same steps performed in the previous sections to integrate
$L_{\rm PV}$ over the fiducial region. As above, we start integrating
over the full range in $|\mathbf{p}_T|$ using the on-shell-ness
$\delta$-function:
\begin{equation}
\begin{array}{c}
\displaystyle \int_0^\infty d|\mathbf{p}_T||\mathbf{p}_T|\,L_{\rm PV}=\frac{\sinh(y-\eta)}{Q}\left[M\cosh(y-\eta)-|\mathbf{q}_T|\cos\phi\right]
\int_0^\infty d|\mathbf{p}_T||\mathbf{p}_T|^3\delta(Q^2-2pq)\\
\\
\displaystyle = \frac{\overline{p}_T^4}{Q^3}\sinh(y-\eta)\left[M\cosh(y-\eta)-|\mathbf{q}_T|\cos\phi\right]\,,
\end{array}
\end{equation}
with $\overline{p}_T$ defined in Eq.~(\ref{eq:overpT}). Now we compute
the indefinte integral over $\cos\phi$. To do so, we need to use
Eq.~(\ref{eq:intoverphi}) along with the equality:
\begin{equation}\label{eq:complicatedintegral3}
\int \frac{dx}{(a\pm
  x)^3\sqrt{1-x^2}}=\frac{\sqrt{1-x^2}\left[3ax\pm(4a^2-1) \right]}{2(a^2-1)^2(x\pm
  a)^2}\pm\displaystyle\frac{(2a^2+1)}{2(a^2-1)^{5/2}}\tan^{-1}\left(\frac{1\pm
      ax}{\sqrt{a^2-1}\sqrt{1-x^2}}\right)\,.
\end{equation}
This allows us to compute the integral(\footnote{The factor
  $\left(\frac {4\pi Q^2}{3}\right)^{-1}$ in
  Eq.~(\ref{eq:Hdefinition}) corresponds to the full phase-space in
  integral of $L_\perp$ in Eq.~(\ref{eq:normalisation}) that provides
  the natural normalisation.}):
\begin{equation}\label{eq:Hdefinition}
\begin{array}{rcl}
\displaystyle H(x,\eta)&=&\displaystyle\left(\frac {4\pi Q^2}{3}\right)^{-1}\frac{\sinh(y-\eta)}{Q^3}\left[M\cosh(y-\eta) \int
  d(\cos\phi)\overline{p}_T^4(\cos\phi)- |\mathbf{q}_T|
  \int d(\cos\phi) \cos\phi\,\overline{p}_T^4(\cos\phi)\right]\\
\\
&=&\displaystyle\frac{3Q^3 \sinh(y-\eta)}{64\pi |\mathbf{q}_T|^4}\left[M\cosh(y-\eta) \int
  \frac{d(\cos\phi)}{\left(a-\cos\phi\right)^4}-|\mathbf{q}_T|\int
  \frac{\cos\phi \,d(\cos\phi)}{\left(a-\cos\phi\right)^4}\right]\\
\\
&=&\displaystyle\frac{3Q^3 \sinh(y-\eta)}{64\pi q_T^3} \int
  \frac{dx}{\sqrt{1-x^2}}\left[\frac{1}{(a-x)^3}+\frac{1}{(a+x)^3}\right]\\
\\
&=&\displaystyle\frac{3Q^3 \sinh(y-\eta)}{128\pi q_T^3}\Bigg\{\frac{\sqrt{1-x^2}}{(a^2-1)^2}\left[\frac{3ax-(4a^2-1) }{(x-
  a)^2}+\frac{3ax+(4a^2-1) }{(x+
  a)^2}\right]\\
\\
&-&\displaystyle\frac{(2a^2+1)}{(a^2-1)^{5/2}}\left[\tan^{-1}\left(\frac{1-
      ax}{\sqrt{a^2-1}\sqrt{1-x^2}}\right) -\tan^{-1}\left(\frac{1+
      ax}{\sqrt{a^2-1}\sqrt{1-x^2}}\right)\right]\Bigg\}
\end{array}
\end{equation}
with $E_q=M\cosh\left(\eta - y\right)$, $q_T=|\mathbf{q}_T|$, and:
\begin{equation}
  a = \frac{E_q}{q_T}\,,
\end{equation}
so that:
\begin{equation}\label{eq:Hfinal}
\begin{array}{rcl}
\displaystyle H(x,\eta)&=&\displaystyle\frac{3Q^3 \sinh(y-\eta)}{128\pi (E_q^2-q_T^2)^{2}}\Bigg\{\sqrt{1-x^2}q_T\left[\frac{3E_qq_Tx-(4E_q^2-q_T^2) }{(xq_T-
  E_q)^2}+\frac{3E_qq_Tx+(4E_q^2-q_T^2) }{(q_Tx+
  E_q)^2}\right]\\
\\
&-&\displaystyle\frac{(2E_q^2+q_T^2)}{\sqrt{E_q^2-q_T^2}}\left[\tan^{-1}\left(\frac{q_T-
      xE_q}{\sqrt{E_q^2-q_T^2}\sqrt{1-x^2}}\right) -\tan^{-1}\left(\frac{q_T+
      xE_q}{\sqrt{E_q^2-q_T^2}\sqrt{1-x^2}}\right)\right]\Bigg\}\,.
\end{array}
\end{equation}
Finally, using the definition of $H$ in Eq.~(\ref{eq:Hfinal}), one can
perform the integral over the fiducial phase space as discussed
above in Eq.~(\ref{eq:finalformula}):
\begin{equation}\label{eq:finalformulaH}
  \mathcal{P}_{\rm PV}(Q,y,q_T)=\displaystyle \int_{\eta_{\rm
      min}}^{\eta_{\rm
      max}}d\eta\,\vartheta(x_2(\eta)-x_1(\eta))\left[H(x_2(\eta),\eta)-H(x_1(\eta) ,\eta)\right]\,.
\end{equation}
This allows one to estimate the impact of the parity-violating
contribution to the phase-space reduction factor.

In order to quantify numerically the impact of
Eq.~(\ref{eq:finalformulaH}), Fig.~\ref{fig:PhaseSpaceRedFactor}
displays the size $\mathcal{P}_{\rm PV}$ relative to the
parity-conserving phase-space reduction factor as a function of $y$
for three different values of $q_T$ at $Q=M_Z$ and for the following
lepton cuts: $p_{T,\ell}>20$ GeV and $-2.4 < \eta_\ell < 2.4$.
\begin{figure}[t]
  \begin{centering}
    \includegraphics[width=0.8\textwidth]{plots/PhaseSpaceRedFactor}
    \caption{Ratio between the parity-violating phase-space reduction
      factor $\mathcal{P}_{\rm PV}$ in Eq.~(\ref{eq:finalformulaH})
      and the respective parity-conserving factor as a function of the
      $Z$ rapidity $y$ at $Q=M_Z$ and for three different values of
      $q_T$, with lepton cuts equal to $p_{T,\ell}>20$~GeV and
      $-2.4 < \eta_\ell < 2.4$.\label{fig:PhaseSpaceRedFactor}}
  \end{centering}
\end{figure}
It turns out that the size of $\mathcal{P}_{\rm PV}$ relative to
$\mathcal{P}$ is never larger than $2\times10^{-6}$. In addition, the
rapid oscillations with $y$ contribute to suppress even more the
integral over realistic bins in $y$. One can thus conclude that, for
realistic kinematic configurations, the impact of parity violating
effects is completely negligible.

% To conclude this section we try to compute analytically the behaviour
% of $\mathcal{P}_{\rm PV}$ in a particular kinematic configuration. For
% $q_T = y = 0$ one has that:
% \begin{equation}
% \displaystyle H(x,\eta)=-\frac{3
%                            \sinh(\eta)}{64\pi \cosh^3(\eta)}\displaystyle \left[\tan^{-1}\left(\frac{x}{\sqrt{1-x^2}}\right) -\tan^{-1}\left(\frac{-x}{\sqrt{1-x^2}}\right)\right]\,.
% \end{equation}

We finally notice that also following contraction enters the game in
the presence of cuts on the leptonic final state:
\begin{equation}
  L_\phi=(z^\mu t^\nu+z^\nu t^\mu)L_{\mu\nu}\,.
\end{equation}
We find that:
\begin{equation}
L_\phi=8(zp)\left[Q-2(tp)\right]\,.
\end{equation}
Using Eqs.~(\ref{eq:pexplicit}) and~(\ref{eq:auxvects}), we
have that:
\begin{equation}
(zp) = p_T(\cosh\eta\sinh y-\sinh\eta\cosh y) = p_T\sinh(y-\eta)\,,
\end{equation}
and:
\begin{equation}
(tp) = \frac1{Q}\left[Mp_T\cosh(y-\eta)-\mathbf{q}_T\cdot
  \mathbf{p}_T\right] = \frac{p_T}{Q}\left[M\cosh(y-\eta)-q_T\cos\phi\right]\,.
\end{equation}
Therefore:
\begin{equation}
L_\phi=16 \frac{p_T^2}{Q}\sinh(y-\eta)\left[\frac{Q^2}{2 p_T
  }-M\cosh(y-\eta)+q_T\cos\phi\right]=16\left[\frac12p_TQ\sinh(y-\eta)-L_{\rm PV}\right]\,.
\end{equation}
Due to the presence of the overall factor $\sinh(y-\eta)$, also this
contribution is expected to be subdominant.

\section{Differential cross section in the leptonic variables}

The calculation of the phase-space reduction factor carried out in the
previous section can be used to express the Drell-Yan cross section in
Eq.~(\ref{eq:crosssection}) as differential in the kinematic variables
of the single leptons. Loosely speaking, this amounts to removing the
integral sign in the numerator in Eq.~(\ref{eq:PSredDef}) but taking
into account kinematic constraints. Using the transverse metric tensor
$g_\perp^{\mu\nu}$, one finds:
\begin{equation}
d\mathcal{P} = \frac{\displaystyle d^4p_1 d^4p_2 \,\delta(p_1^2) \delta(p_2^2)\theta(p_{1,0}) \theta(p_{2,0})\delta^{(4)}(p_1+p_2-q) L_\perp(p_1,p_2)}{\displaystyle \int d^4p_1 d^4p_2\, \delta(p_1^2) \delta(p_2^2) \theta(p_{1,0}) \theta(p_{2,0})\delta^{(4)}(p_1+p_2-q) L_\perp(p_1,p_2)}\,,
\end{equation}
From Eq.~(\ref{eq:normalisation}), we know the value of the
denominator. In the numerator, we can make use of the
momentum-conservation and one of the on-shell-ness
$\delta$-functions. Using the r.h.s. of
Eq.~(\ref{eq:firstintegralNew}), but integrating over $\phi$ rather
than $|\mathbf{p}_T|$, leads to:
\begin{equation}
\frac{d\mathcal{P}}{d|\mathbf{p}_T|d\eta} = \frac {3 |\mathbf{p}_T|}{4\pi}\left[1+4 \sinh^2(y-\eta)\frac{|\mathbf{p}_T|^2}{Q^2}\right]
 \int_0^{2\pi} d\phi\,\delta(Q^2-2 |\mathbf{p}_T|\left[M\cosh\left(\eta - y\right)-|\mathbf{q}_T|\cos\phi\right])\,,
\end{equation}
where we have used
Eqs.~(\ref{eq:phasespacemeasure})-(\ref{eq:integralyeah!}) and
Eq.~(\ref{eq:deltaargument}). Finally, to perform the integral over
$\phi$ we use Eq.~(\ref{eq:intoverphi}) to get:
\begin{equation}\label{eq:difflepphasespace}
\frac{d\mathcal{P}}{d|\mathbf{p}_T|d\eta} = \frac {3|\mathbf{p}_T|}{2\pi Q^2}
 \frac{Q^2+4 |\mathbf{p}_T|^2 \sinh^2(\eta-y)}{\sqrt{4|\mathbf{p}_T|^2|\mathbf{q}_T|^2-(2|\mathbf{p}_T|M\cosh(\eta-y)-Q^2)^2}}\,.
\end{equation}
Getting rid of the absolute value of the transverse vectors, this
allows one to get the Drell-Yan cross section differential in the
leptonic variables $|\mathbf{p}_T|$ and $\eta$:
\begin{equation}
\frac{d\sigma}{dQ dy dq_T d\eta dp_T} =
                                                          \left[\frac
                                                          {3p_T^2}{\pi
                                                          Q^2 M}\frac{\left(\frac{Q^2}{4 p_T^2}-1\right)+\cosh^2(\eta-y)}{\sqrt{\frac{q_T^2}{M^2}-\left(\cosh(\eta-y)-\frac{Q^2}{2p_TM}\right)^2}}\right]\frac{d\sigma}{dQ dy dq_T}\,.
\end{equation}
Due to the square root in the denominator, for fixed values of $Q$,
$q_T$, and $y$, the expression above is defined for values of $p_T$
and $\eta$ such that:
\begin{equation}\label{eq:kinconstr}
\frac{Q^2}{2p_TM}-\frac{q_T }{M}< \cosh(\eta-y) < \frac{Q^2}{2p_TM}+\frac{q_T}{M}\,.
\end{equation}

In order to focus on the $p_T$ dependence of the cross section, one
may want to integrate of the lepton rapidity $\eta$. Using the
analogous of Eq.~(\ref{eq:intoverphi}) for $\cosh(\eta)$:
\begin{equation}\label{eq:intovereta}
\int_{-\infty}^{\infty}d\eta\, f(\cos\eta) = \int_{1}^{\infty}\frac{dx}{\sqrt{x^2-1}}\left[f(x)+f(-x)\right]\,,
\end{equation}
and taking into account the constraint in Eq.~(\ref{eq:kinconstr}),
one finds:
\begin{equation}\label{eq:LeptonicModulation}
\begin{array}{l}
\displaystyle \frac{d\sigma}{dQ dy dq_T dp_T} =\frac{d\sigma}{dQ dy
  dq_T} \times\\
\\
\displaystyle\frac
                                                          {3p_T}{2\pi
                                                          Q^2}\int_{-\frac{q_T}{M}}^{\frac{q_T}{M}}
  \frac{dy}{\sqrt{\frac{q_T^2}{M^2}-y^2}}\left(\frac{\left(\frac{Q^2}{4
  p_T^2}-1\right)+\left(y+\frac{Q^2}{2p_TM}\right)^2}{\sqrt{\left(y+\frac{Q^2}{2p_TM}\right)^2-1}}+\frac{\left(\frac{Q^2}{4
  p_T^2}-1\right)+\left(y-\frac{Q^2}{2p_TM}\right)^2}{\sqrt{\left(y-\frac{Q^2}{2p_TM}\right)^2-1}}\right)\,.
\end{array}
\end{equation}
For fixed values of $Q$, $q_T$, and $y$, the integral above can be
solved numerically and plotted as a function of $p_T$. The result is
shown in Fig.~\ref{fig:LeptonicModulation}.
\begin{figure}[t]
  \begin{centering}
    \includegraphics[width=0.8\textwidth]{plots/LeptonicModulation}
    \caption{Behaviour of the second line of
      Eq.~(\ref{eq:LeptonicModulation}) at $Q=M_Z$ and $y=0$ as a
      function of the lepton transverse momentum
      $p_{T,\ell}$.\label{fig:LeptonicModulation}}
  \end{centering}
\end{figure}

\section{Convolution in transverse-momentum space}

The ``transverse-momentum'' version of Eq.~(\ref{eq:crosssection}) reads:
\begin{equation}\label{eq:crosssectionkt}
\begin{array}{rcl}
  \displaystyle \frac{d\sigma}{dQ dy dq_T} &=&\displaystyle 
  \frac{16\pi\alpha^2q_T}{9 Q^3} H(Q,\mu) \sum_q C_q(Q)\\
\\
&\times&\displaystyle 
  \int d^2\mathbf{k}_{T,1}d^2\mathbf{k}_{T,2}
  \overline{F}_q(x_1,\mathbf{k}_{T,1};\mu,\zeta)
  \overline{F}_{\bar{q}}(x_2,\mathbf{k}_{T,2};\mu,\zeta)\delta^{(2)}(\mathbf{q}_{T}-\mathbf{k}_{T,1}-\mathbf{k}_{T,2})\,,
\end{array}
\end{equation}
where, with abuse of notation, we used the same symbol for the
distributions $F$ both in $k_T$ and $b_T$ space. We can make use of
the $\delta$-function to reduce the expression above to:
\begin{equation}\label{eq:crosssectionkt2}
\frac{d\sigma}{dQ dy dq_T} =\frac{16\pi\alpha^2q_T}{9 Q^3} H(Q,\mu) \sum_q C_q(Q)\int d^2\mathbf{k}_{T}
  \overline{F}_q(x_1,\mathbf{k}_{T};\mu,\zeta)
  \overline{F}_{\bar{q}}(x_2,\mathbf{q}_{T}-\mathbf{k}_{T};\mu,\zeta)\,.
\end{equation}
Since the distributions $F$ only depend on the absolute value of their
argument (be it $k_T$ or $b_T$), the expression above can be further
reduced to:
\begin{equation}\label{eq:crosssectionkt3}
\begin{array}{rcl}
\displaystyle \frac{d\sigma}{dQ dy dq_T} &=&\displaystyle
                                             \frac{16\pi\alpha^2q_T}{9
                                             Q^3} H(Q,\mu) \sum_q
                                             C_q(Q)\\
\\
&\times&\displaystyle \int_0^\infty dk_{T}\,k_{T}\int_0^{2\pi}d\theta\,
  \overline{F}_q(x_1,k_T;\mu,\zeta)
  \overline{F}_{\bar{q}}(x_2,\sqrt{q_{T}^2+k_{T}^2
  -2q_{T}k_{T}\cos\theta};\mu,\zeta)\,,
\end{array}
\end{equation}
where, without loss of generality, we are assuming that the vector
$\mathbf{q}_T$ is directed along the $x$ axis. Knowing the functions
$F$ in $k_T$ space, the formula above can be implemented numerically.

\section{The $A_0$ coefficient}

Using Eq.~(5) of Ref.~\cite{Richter-Was:2016mal}, the azimuthal angle
$\theta$ of the (negative) lepton in the Collins-Soper frame can be
related to the momenta on the vector boson and of one of the leptons
in the laboratory frame as:
\begin{equation}\label{eq:RitterSport}
\cos\theta(\eta,p_T) = \mbox{sign}(y)\frac{2p_T}{Q}\sinh(y-\eta).
\end{equation}
This can be related to the coefficient $A_0$ as~\cite{Gauld:2017tww}:
\begin{equation}
A_0= 4 - 10\,\langle\cos^2\theta\rangle\,,
\end{equation}
where:
\begin{equation}
\begin{array}{rcl}
\displaystyle \langle\cos^2\theta\rangle &\equiv& \displaystyle  \left[\int dp_Td\eta
  \frac{d\sigma}{dQdydq_T d\eta dp_T}\right]^{-1}\int
  dp_Td\eta\left[\cos\theta(\eta, p_T)\right]^2 \frac{d\sigma}{dQdydq_T d\eta dp_T}\,.
\end{array}
\end{equation}
If the integration in both numerator and denominator in the r.h.s. of
the quantity above is performed over the full phase space, the result
at small $q_T$ is:
\begin{equation}
\langle\cos^2\theta\rangle =\int
  dp_Td\eta\left[\cos\theta(\eta, p_T)\right]^2 \frac{d\mathcal{P}}{dp_Td\eta}\,
\end{equation}
with the element of phase space $d\mathcal{P}$ is given in
Eq.~(\ref{eq:difflepphasespace}). Therefore, the ``QCD dynamics''
totally cancels in the ration and one is left with a relatively
interesting kinematic factor.

\section{Implementing the $\phi*$ distribution}

A physical observable that is particularly useful to probe the
intrinsic transverse dynamics of hadrons is the so-called $\phi^*$
distribution in Drell-Yan production, defined as~\cite{Banfi:2010cf}:
\begin{equation}
\phi^*=\tan\left(\frac{\pi-\Delta\phi}{2}\right)\sin\theta^*=\tan\left(\frac{\pi-\Delta\phi}{2}\right)\sqrt{1-\tanh^2\left(\frac{\Delta\eta}{2}\right)}\,,
\end{equation}
where $\Delta\phi = \phi_1-\phi_2$ and $\Delta\eta = \eta_1-\eta_2$
are the separation in azimuthal angle and pseudo-rapidity of the two
outgoing leptons. The reason why $\phi^*$ is interesting is that
experimental measurements of this quantity reach an extremely high
accuracy. It is therefore useful to express the Drell-Yan cross
section differential in $q_T$ into a cross section differential in
$\phi^*$. This is achieved through the chain rule:
\begin{equation}
\frac{d\sigma}{dQdydq_T d\eta dp_T} = \frac{d\phi^*}{dq_T}\frac{d\sigma}{dQdyd\phi^*d\eta dp_T}\,.
\end{equation}
Of course, this requires the knowledge of $\phi^*$ as a function of
$q_T$ which is what we will work out in the following. The starting
point is the four-momentum conservation $q=p_1+p_2$. Taking the
absolute value
of this relation and using the parameterisations in
Eq.~(\ref{eq:qexplicit}) for $q$ and in Eq.~(\ref{eq:pexplicit}) for
both $p_1$ and $p_2$ immediately gives:
\begin{equation}\label{eq:coshdeta}
\cosh\Delta\eta = 1+\frac{Q^2}{2p_{T1}p_{T2}}\,. 
\end{equation}
In addition, equating the absolute values of the transverse component
($|\mathbf{q}_T|^2=|\mathbf{p}_{T1}+\mathbf{p}_{T2}|^2$) leads to:
\begin{equation}\label{eq:cosdphi}
\cos\Delta\phi =\frac{p_{T1}^2+p_{T2}^2-q_T^2}{2p_{T1}p_{T2}}\,.
\end{equation}
Using Eq.~(\ref{eq:coshdeta}) one has:
\begin{equation}
\tanh\left(\frac{\Delta\eta}{2}\right) =
\sqrt{\frac{\cosh\Delta\eta-1}{\cosh\Delta\eta+1}} = \sqrt{\frac{Q^2}{Q^2+4p_{T1}p_{T2}}}\,,
\end{equation}
so that:
\begin{equation}
\sin\theta^*=\sqrt{1-\tanh^2\left(\frac{\Delta\eta}{2}\right)}
=\sqrt{\frac{4p_{T1}p_{T2}}{Q^2 + 4p_{T1}p_{T2}}}\,.
\end{equation}
On the other hand, using Eq.~(\ref{eq:cosdphi}) one finds:
\begin{equation}
\tan\left(\frac{\pi-\Delta\phi}{2}\right) = \sqrt{\frac{1-\cos(\pi-\Delta\phi)}{1+\cos(\pi-\Delta\phi)}}=\sqrt{\frac{1+\cos\Delta\phi}{1-\cos\Delta\phi}}=\sqrt{\frac{p_{T1}^2+p_{T2}^2-q_T^2+2p_{T1}p_{T2}}{p_{T1}^2+p_{T2}^2-q_T^2-2p_{T1}p_{T2}}}\,.
\end{equation}
Now let us define $p_{T1}=p_T$ and $\eta=\eta_1$ and trade $p_{T2}$
for $\cosh(y-\eta)$ using the relation:
\begin{equation}
p_{T2}^2=M^2+p_T^2-2p_TM\cosh(y-\eta)
\end{equation}
with $M=\sqrt{Q^2+q_T^2}$. This gives:
\begin{equation}
\sin\theta^*=\sqrt{\frac{4p_{T}\sqrt{M^2+p_T^2-2p_TM\cosh(y-\eta)}}{Q^2 +4p_{T}\sqrt{M^2+p_T^2-2p_TM\cosh(y-\eta)}}}\,.
\end{equation}
and:
\begin{equation}
\tan\left(\frac{\pi-\Delta\phi}{2}\right) = \sqrt{\frac{Q^2+2p_T\left[p_T-M\cosh(y-\eta)+\sqrt{M^2+p_T^2-2p_TM\cosh(y-\eta)}\right]}{Q^2+2p_T\left[p_T-M\cosh(y-\eta)-\sqrt{M^2+p_T^2-2p_TM\cosh(y-\eta)}\right]}}\,.
\end{equation}
Gathering all pieces together finally gives:
\begin{equation}\label{eq:phistarmaster}
\begin{array}{rcl}
\phi^*&=&\displaystyle
          \sqrt{\frac{Q^2+2p_T\left[p_T-M\cosh(y-\eta)+\sqrt{M^2+p_T^2-2p_TM\cosh(y-\eta)}\right]}{Q^2+2p_T\left[p_T-M\cosh(y-\eta)-\sqrt{M^2+p_T^2-2p_TM\cosh(y-\eta)}\right]}}\\
\\
&\times& \displaystyle\sqrt{\frac{4p_{T}\sqrt{M^2+p_T^2-2p_TM\cosh(y-\eta)}}{Q^2 +4p_{T}\sqrt{M^2+p_T^2-2p_TM\cosh(y-\eta)}}}\,.
\end{array}
\end{equation}

One can show that the boost required to go from the laboratory frame,
in which the vectors $q$ and $p$ are given by
Eqs.~(\ref{eq:qexplicit}) and~(\ref{eq:pexplicit}), respectively, with
$p_T$ given by Eq.~(\ref{eq:overpT}), to the Collins-Soper frame, in
which:
\begin{equation}\label{eq:CSdecomp}
q = Q(1,0,0,0)\quad\mbox{and}\quad p = \frac{Q}2(1,\sin\theta\cos\phi, \sin\theta\sin\phi,\cos\theta)\,,
\end{equation}
is given by:
\begin{equation}\label{eq:boostLabToCS}
\Lambda_{{\rm Lab}\rightarrow {\rm CS}} = 
\begin{pmatrix}
\frac{M}{Q}\cosh y & -\frac{q_T}{Q} & 0 & -\frac{M}{Q}\sinh y\\
-\frac{q_T}{Q}\cosh y & \frac{M}{Q} & 0 & \frac{q_T}{Q}\sinh y\\
0 & 0 & 1 & 0 \\
-\sinh y & 0 & 0 & \cosh y
\end{pmatrix}\,,
\end{equation}
with $M=\sqrt{Q^2+q_T^2}$. Likewise, the boost to go from the
Collins-Soper to the laboratory frame is the inverse of the above
transformation and reads:
\begin{equation}\label{eq:boostCSToLab}
\Lambda_{ {\rm CS}\rightarrow{\rm Lab}} = \Lambda_{{\rm Lab}\rightarrow {\rm CS}}^{-1}=
\begin{pmatrix}
\frac{M}{Q}\cosh y & \frac{q_T}{Q}\cosh y & 0 & \sinh y\\
\frac{q_T}{Q} & \frac{M}{Q} & 0 & 0\\
0 & 0 & 1 & 0 \\
\frac{M}{Q}\sinh y & \frac{q_T}{Q}\sinh y & 0 & \cosh y
\end{pmatrix}\,.
\end{equation}
Notice that rotating the vector in Eq.~(\ref{eq:pexplicit}) using the
transformation in Eq.~(\ref{eq:boostLabToCS}) and equating the $z$
component to that of the vector $p$ in Eq.~(\ref{eq:CSdecomp})
immediately gives Eq.~(\ref{eq:RitterSport}). This immediately allows
one to write:
\begin{equation}
\sin\theta = \frac{\sqrt{Q^2-4p_T\sinh^2(\eta-y)}}{Q}
\end{equation}



\newpage

\begin{thebibliography}{alp}

%\cite{Scimemi:2017etj}
\bibitem{Scimemi:2017etj}
  I.~Scimemi and A.~Vladimirov,
  %``Analysis of vector boson production within TMD factorization,''
  arXiv:1706.01473 [hep-ph].
  %%CITATION = ARXIV:1706.01473;%%
  %2 citations counted in INSPIRE as of 24 Oct 2017

%\cite{Collins:2011zzd}
\bibitem{Collins:2011zzd}
  J.~Collins,
  %``Foundations of perturbative QCD,''
  Camb.\ Monogr.\ Part.\ Phys.\ Nucl.\ Phys.\ Cosmol.\  {\bf 32} (2011) 1.
  %%CITATION = CMPCE,32,1;%%
  %327 citations counted in INSPIRE as of 21 Oct 2018

\bibitem{Ogata:quadrature}
  H.~Ogata,
  ``A Numerical Integration Formula Based on the Bessel Functions,''
  \texttt{http://www.kurims.kyoto-u.ac.jp/$\sim$okamoto/paper/Publ\_RIMS\_DE/41-4-40.pdf}

%\cite{Banfi:2010cf}
\bibitem{Banfi:2010cf}
A.~Banfi, S.~Redford, M.~Vesterinen, P.~Waller and T.~R.~Wyatt,
%``Optimisation of variables for studying dilepton transverse momentum distributions at hadron colliders,''
Eur. Phys. J. C \textbf{71} (2011), 1600
doi:10.1140/epjc/s10052-011-1600-y
[arXiv:1009.1580 [hep-ex]].
%108 citations counted in INSPIRE as of 23 Oct 2020

%\cite{Catani:2015vma}
\bibitem{Catani:2015vma}
S.~Catani, D.~de Florian, G.~Ferrera and M.~Grazzini,
%``Vector boson production at hadron colliders: transverse-momentum resummation and leptonic decay,''
JHEP \textbf{12} (2015), 047
doi:10.1007/JHEP12(2015)047
[arXiv:1507.06937 [hep-ph]].
%88 citations counted in INSPIRE as of 23 Oct 2020

%\cite{Richter-Was:2016mal}
\bibitem{Richter-Was:2016mal}
E.~Richter-Was and Z.~Was,
%``Separating electroweak and strong interactions in Drell\textendash{}Yan processes at LHC: leptons angular distributions and reference frames,''
Eur. Phys. J. C \textbf{76} (2016) no.8, 473
doi:10.1140/epjc/s10052-016-4319-y
[arXiv:1605.05450 [hep-ph]].
%12 citations counted in INSPIRE as of 21 Nov 2020

%\cite{Gauld:2017tww}
\bibitem{Gauld:2017tww}
R.~Gauld, A.~Gehrmann-De Ridder, T.~Gehrmann, E.~W.~N.~Glover and A.~Huss,
%``Precise predictions for the angular coefficients in Z-boson production at the LHC,''
JHEP \textbf{11} (2017), 003
doi:10.1007/JHEP11(2017)003
[arXiv:1708.00008 [hep-ph]].
%32 citations counted in INSPIRE as of 21 Nov 2020

\end{thebibliography}

\end{document}
